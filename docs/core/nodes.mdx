---
title: Nodes
description: 'The atomic unit of computation.'
---

The `Node` is the atomic unit of computation in HyperNodes. It wraps a standard Python function with metadata that allows it to be part of a dependency graph.

## Creating a Node

The simplest way to create a node is using the `@node` decorator.

```python
from hypernodes import node

@node
def add_one(x: int) -> int:
    return x + 1
```

### Output Names

By default, the output name of the node in the pipeline results will be the function name (`add_one` in the example above).

You can customize this:

```python
@node(output_name="result")
def add_one(x: int) -> int:
    return x + 1
```

### Multiple Outputs

If your function returns multiple values, you can specify a tuple of output names. The function should return a tuple (or list) of corresponding length.

```python
@node(output_name=("quotient", "remainder"))
def divide(a: int, b: int) -> tuple:
    return a // b, a % b
```

These outputs become available independently to downstream nodes. One node might depend on `quotient`, while another depends on `remainder`.

## Dependencies (Root Args)

HyperNodes analyzes the signature of your function to determine its inputs (`root_args`).

```python
@node
def combine(a, b): ...
```

Here, `a` and `b` are dependencies.
- If `a` is the output of another node, HyperNodes links them.
- If `a` is provided in the `inputs` dictionary to `pipeline.run()`, it's treated as a root input.

This allows implicit graph construction without manual edge definitions.

## Async Nodes

HyperNodes natively supports `async def` functions. This is ideal for I/O-bound operations like API calls or database queries.

```python
import asyncio

@node
async def fetch_data(url: str) -> str:
    await asyncio.sleep(0.1)  # Simulate I/O
    return f"Data from {url}"
```

When running with an engine that supports async (like the default `SeqEngine` or `DaskEngine`), these nodes will be executed efficiently, potentially concurrently.

## Code Hashing

One of HyperNodes' most powerful features is **Code Hashing**.

When you define a node, HyperNodes computes a SHA256 hash of the function's source code. This hash is part of the cache key.

- **Change the code?** -> Hash changes -> Cache invalidates -> Node re-runs.
- **Same code?** -> Hash stays same -> Cache hit -> Instant result.

This happens automatically. You don't need to version your functions manually.

```python
# If I change 1 to 2 here, the next run will automatically re-execute.
@node
def unstable_func(x):
    return x + 1 
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Pipelines" icon="sitemap" href="./pipelines">
    Connect nodes into workflows.
  </Card>
  <Card title="Dual Nodes" icon="bolt" href="../composition/dual-nodes">
    Optimize for batch execution.
  </Card>
</CardGroup>

---
title: Stateful Parameters
description: 'Managing heavy resources.'
---

In ML pipelines, you often need to manage "heavy" resources that should be initialized once and reused across many items, such as:
- Machine Learning Models
- Database Connections
- API Clients

HyperNodes handles this via **Stateful Parameters**.

## The Problem

If you just pass a model as a regular input to a map, it might get serialized/deserialized repeatedly, or worse, re-initialized for every item.

## The Solution

Mark the class as `@stateful` (or ensure it has `__hypernode_stateful__ = True`).

```python
from hypernodes import stateful

@stateful
class TextModel:
    def __init__(self, path):
        print("Loading model...")
        self.model = load_heavy_model(path)
        
    def predict(self, text):
        return self.model(text)
```

Now, pass an instance of this class as an input to your pipeline.

```python
@node
def classify(text: str, model: TextModel) -> str:
    return model.predict(text)

# Create ONE instance
my_model = TextModel("path/to/weights")

# Map over 1000 texts
results = pipeline.map(
    inputs={
        "text": ["hello", "world", ...], 
        "model": my_model  # Passed as a handle
    },
    map_over="text"
)
```

## How it works with Engines

- **SequentialEngine**: The object is passed by reference. It stays in memory.
- **DaftEngine**: Daft treats this as a "Stateful UDF". The object is initialized once per worker process and reused for the entire batch/partition.

This ensures efficient resource usage even in distributed settings.


---
title: Daft Map Over Support
description: 'Distributed batch processing with map_over in DaftEngine.'
---

DaftEngine fully supports `.as_node(map_over=...)` for efficient distributed data processing.

## Overview

When you use `map_over` with DaftEngine, it translates the operation into native Daft DataFrame transformations:

1. **Explode**: Converts lists into rows
2. **Transform**: Applies the pipeline to each row (distributed)
3. **Aggregate**: Collects results back into lists

## Example

```python
from hypernodes import Pipeline, node, DaftEngine

# 1. Define a single-item node
@node(output_name="doubled")
def double(x: int) -> int:
    return x * 2

# 2. Create a mapped node
double_pipeline = Pipeline(nodes=[double])
double_many = double_pipeline.as_node(
    input_mapping={"numbers": "x"},
    output_mapping={"doubled": "all_doubled"},
    map_over="numbers"
)

# 3. Run with DaftEngine
pipeline = Pipeline(nodes=[double_many], engine=DaftEngine())
result = pipeline.run(inputs={"numbers": [1, 2, 3]})
# result["all_doubled"] == [2, 4, 6]
```

## How It Works

DaftEngine optimizes this pattern by:
- **Lazy Evaluation**: The explode/transform/aggregate steps are planned but not executed until needed.
- **Parallelism**: Operations are automatically distributed across available cores.
- **Vectorization**: Where possible, operations are batched.

## Performance

### Advantages
- ✅ **Automatic Parallelization**: Uses all available cores
- ✅ **Memory Efficient**: Streaming execution for large datasets
- ✅ **Type Safety**: Daft's type system ensures consistency

### Considerations
- ⚠️ **Row IDs**: Adds a temporary row ID column for reconstruction
- ⚠️ **Single Column**: Currently supports mapping over one column at a time

## See Also

- [DaftEngine Overview](./daft-engine)
- [Nested Pipelines](../essentials/nested-pipelines)

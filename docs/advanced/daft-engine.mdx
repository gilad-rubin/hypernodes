---
title: Daft Engine
description: 'Distributed execution with Daft DataFrames.'
---

The `DaftEngine` automatically converts HyperNodes pipelines into [Daft](https://www.getdaft.io/) DataFrames, providing lazy evaluation, automatic optimization, and high-performance execution.

## Overview

DaftEngine translates HyperNodes pipelines into Daft operations:
- **Nodes** → Daft UDFs (`@daft.func`)
- **Map operations** → DataFrame operations
- **Pipelines** → Lazy DataFrame transformations

### Key Benefits

1. **Lazy Evaluation**: Operations are optimized before execution
2. **Automatic Parallelization**: No manual configuration needed
3. **Performance**: Optimized execution with vectorization
4. **Scalability**: Designed for distributed execution
5. **Zero Code Changes**: Drop-in replacement for HypernodesEngine

## Installation

```bash
pip install daft
# or
uv add daft
```

## Basic Usage

### Simple Pipeline

```python
from hypernodes import node, Pipeline
from hypernodes.engines import DaftEngine

@node(output_name="result")
def add_one(x: int) -> int:
    return x + 1

# Use DaftEngine
pipeline = Pipeline(nodes=[add_one], engine=DaftEngine())
result = pipeline.run(inputs={"x": 5})
# result == {"result": 6}
```

### Map Operations

```python
@node(output_name="doubled")
def double(x: int) -> int:
    return x * 2

pipeline = Pipeline(nodes=[double], engine=DaftEngine())

# Process multiple items
results = pipeline.map(inputs={"x": [1, 2, 3, 4, 5]}, map_over="x")
# results == {"doubled": [2, 4, 6, 8, 10]}
```

## Advanced Features

### Nested Pipelines

DaftEngine automatically handles nested pipelines:

```python
@node(output_name="cleaned")
def clean_text(text: str) -> str:
    return text.strip().lower()

@node(output_name="word_count")
def count_words(cleaned: str) -> int:
    return len(cleaned.split())

# Inner pipeline
preprocess = Pipeline(nodes=[clean_text, count_words])

@node(output_name="is_long")
def classify(word_count: int) -> bool:
    return word_count > 3

# Outer pipeline with DaftEngine
full_pipeline = Pipeline(
    nodes=[preprocess, classify],
    engine=DaftEngine()
)

result = full_pipeline.run(inputs={"text": "  Hello World  "})
# result == {"cleaned": "hello world", "word_count": 2, "is_long": False}
```

### Execution Plan Visualization

View Daft's execution plan before running:

```python
engine = DaftEngine(show_plan=True)
pipeline = Pipeline(nodes=[...], engine=engine)
result = pipeline.run(inputs={...})
# Prints the optimized execution plan
```

### Selective Output

Request only specific outputs:

```python
@node(output_name="step1")
def step_one(x: int) -> int:
    return x * 2

@node(output_name="step2")
def step_two(step1: int) -> int:
    return step1 + 10

@node(output_name="final")
def step_three(step2: int) -> int:
    return step2 ** 2

pipeline = Pipeline(nodes=[step_one, step_two, step_three], engine=DaftEngine())

# Get only final result
result = pipeline.run(inputs={"x": 5}, output_name="final")
# result == {"final": 400}

# Get multiple specific outputs
result = pipeline.run(inputs={"x": 5}, output_name=["step1", "final"])
# result == {"step1": 10, "final": 400}
```

## Configuration Options

### DaftEngine Parameters

```python
DaftEngine(
    use_batch_udf=True,       # Use vectorized UDFs where possible (default: True)
    default_daft_config=None  # Optional Daft config dict
)
```

- **use_batch_udf**: If `True`, attempts to use Daft's batch UDFs for better performance.
- **default_daft_config**: Dictionary of configuration options passed to Daft.


## Performance Considerations

### When to Use DaftEngine

✅ **Use DaftEngine when:**
- Processing large datasets (>1GB)
- Performance is critical
- You want automatic optimization
- You need distributed execution
- Operations can be vectorized

❌ **Use HypernodesEngine when:**
- You need explicit DAG visualization
- Fine-grained caching at node level is important
- Complex branching logic with inspection
- Small datasets (<1MB)
- Debugging intermediate results

### Optimization Tips

1. **Batch Operations**: Daft automatically optimizes operations across rows
2. **Lazy Evaluation**: Build complex pipelines without immediate execution
3. **Selective Outputs**: Request only needed outputs to skip unnecessary computation
4. **Type Hints**: Provide type hints for better optimization

## Comparison with HypernodesEngine

| Feature | HypernodesEngine | DaftEngine |
|---------|------------------|------------|
| Execution | Sequential/Async/Threaded/Parallel | Lazy + Optimized |
| Parallelization | Manual configuration | Automatic |
| Optimization | None | Query optimization |
| Caching | Node-level | DataFrame-level |
| Visualization | DAG graphs | Execution plans |
| Distributed | Custom executors | Native support |
| Best for | Development, debugging | Production, performance |

## Deep Dive

Explore advanced DaftEngine topics:

<CardGroup cols={2}>
  <Card title="Complex Types" icon="code" href="./daft-engine-complex-types">
    How DaftEngine handles Pydantic models and nested structures.
  </Card>
  <Card title="Type Inference" icon="wand-magic-sparkles" href="./automatic-type-inference-for-daft">
    Automatic type inference for Python objects.
  </Card>
  <Card title="Map Over Support" icon="layer-group" href="./daft-engine-map-over-support">
    Distributed batch processing with `.map_over`.
  </Card>
  <Card title="Stateful Objects" icon="database" href="./stateful-objects">
    Managing expensive resources with Daft.
  </Card>
</CardGroup>

## Limitations

### Current Limitations

1. **Callbacks**: Callback context is not fully integrated (progress bars, tracing)
2. **Caching**: Uses Daft's caching, not HyperNodes' node-level cache
3. **Custom Executors**: Uses Daft's execution engine

### Planned Features

- [ ] Support for `@daft.func.batch` for vectorized operations
- [ ] Generator functions with `Iterator[T]` type hints
- [ ] Async functions for I/O-bound operations
- [ ] Integration with HyperNodes callbacks
- [ ] Custom resource requirements (GPUs, memory)

## Examples

See the following examples:
- `examples/daft_backend_example.py` - Comprehensive examples
- `notebooks/hypernodes_to_daft.ipynb` - Interactive tutorial
- `notebooks/DAFT_TRANSLATION_GUIDE.md` - Translation patterns

## Troubleshooting

### Import Error

```
ImportError: Daft is not installed
```

**Solution**: Install Daft with `pip install daft` or `uv add daft`

### Type Inference Issues

If Daft cannot infer types, provide explicit type hints:

```python
@node(output_name="result")
def process(x: int) -> list[str]:  # Explicit return type
    return [str(x)]
```

### Performance Not Improved

- Check dataset size (Daft shines with larger datasets)
- Use `show_plan=True` to inspect optimization
- Consider using `@daft.func.batch` for vectorized operations (future)

## See Also

- [Daft Documentation](https://www.getdaft.io/)
- [Daft UDF Guide](https://www.getdaft.io/projects/docs/en/stable/user_guide/udf.html)
- [HyperNodes Documentation](../introduction)


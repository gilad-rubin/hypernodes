---
title: Introduction
description: 'Hierarchical, Modular Data Pipelines for AI/ML'
---

<img
  className="block dark:hidden"
  src="/assets/light_background_logo.png"
  alt="Hero Light"
/>
<img
  className="hidden dark:block"
  src="/assets/dark_background_logo.png"
  alt="Hero Dark"
/>

HyperNodes is a **hierarchical, modular pipeline system** designed for ML/AI development. It enables you to **define your logic on a single item**, then compose and scale seamlessly.

![Pipeline Overview](/docs/assets/pipeline_overview.svg)

## Why HyperNodes?

<CardGroup cols={2}>
  <Card title="Simplicity First" icon="cube">
    Define functions on a single item (e.g., one PDF). Easy to test, debug, and reason about.
  </Card>
  <Card title="Hierarchical Modularity" icon="sitemap">
    Functions are nodes. Pipelines are nodes. Nest pipelines infinitely to compose complex systems.
  </Card>
  <Card title="Structured Data" icon="code">
    Built-in support for Pydantic and dataclasses. Keep your data structured and type-safe.
  </Card>
  <Card title="Daft Integration" icon="rocket">
    Scale effortlessly. Distributed execution and intelligent caching powered by Daft.
  </Card>
</CardGroup>

## Installation

<CodeGroup>
  ```bash uv
  uv add hypernodes
  ```

  ```bash pip
  pip install hypernodes
  ```
</CodeGroup>

To use the distributed engine features:

```bash
pip install "hypernodes[daft]"
```

## Quick Example

Define nodes and build a pipeline in just a few lines:

```python
from hypernodes import node, Pipeline

# 1. Define functions on a single item
@node(output_name="cleaned_text")
def clean_text(passage: str) -> str:
    return passage.strip().lower()

@node(output_name="word_count")
def count_words(cleaned_text: str) -> int:
    return len(cleaned_text.split())

# 2. Build pipeline
pipeline = Pipeline(nodes=[clean_text, count_words])

# 3. Test with single input
result = pipeline.run(inputs={"passage": "  Hello World  "})
# {'cleaned_text': 'hello world', 'word_count': 2}
```

![Simple Pipeline](/docs/assets/pipeline_simple.svg)

HyperNodes automatically resolves dependencies by matching parameter names to output names. The visualization shows how data flows through your pipeline.

## Documentation Guide

<CardGroup cols={2}>
  <Card title="Core Concepts" icon="book" href="/docs/core/nodes">
    Learn about Nodes, Pipelines, and Execution.
  </Card>
  <Card title="Data Processing" icon="layer-group" href="/docs/composition/nesting">
    Master composition with Nesting and Mapping.
  </Card>
  <Card title="Scaling" icon="server" href="/docs/scaling/daft-engine">
    Scale from one item to millions with Daft.
  </Card>
  <Card title="Observability" icon="chart-line" href="/docs/observability/visualization">
    Visualize and monitor your pipelines.
  </Card>
</CardGroup>

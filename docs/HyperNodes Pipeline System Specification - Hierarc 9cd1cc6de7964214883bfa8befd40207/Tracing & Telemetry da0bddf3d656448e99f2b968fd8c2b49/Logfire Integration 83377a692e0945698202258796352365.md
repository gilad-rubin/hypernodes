# Logfire Integration

# Overview

**Logfire** is the default telemetry implementation for the pipeline system. Built on OpenTelemetry, Logfire provides a modern, async-friendly API for distributed tracing, structured logging, and real-time visualization—perfectly aligned with the pipeline system's principles of observability and hierarchical execution.

---

# Why Logfire?

**Async-Native**

Logfire natively supports async Python, capturing traces and logs across async boundaries, threads, and distributed services without manual instrumentation.

**OpenTelemetry Foundation**

Built on OpenTelemetry's tracing model (spans, context propagation), Logfire integrates seamlessly with the broader observability ecosystem and existing exporters.

**Context Propagation**

Automatic and manual context propagation ensures trace continuity across process and network boundaries—essential for remote execution on Modal, Coiled, and other backends.

**Real-Time Visualization**

Live waterfall charts, interactive dashboards, and notebook widgets provide immediate feedback on pipeline execution, including remote and distributed jobs.

**Remote Monitoring**

Telemetry streams from remote workers back to your local environment, enabling real-time monitoring of cloud-based workflows from Jupyter notebooks or CLI.

---

# Integration Architecture

## LogfireCallback

The `LogfireCallback` implements the [Intelligent Callback System](../Intelligent%20Callback%20System%20be7cb6cd6a5f419fb949210a31497a73.md) interface, providing telemetry hooks at every lifecycle event:

```python
from pipeline_system import LogfireCallback
import logfire

class LogfireCallback:
    def __init__(self, export_to: str = "cloud", trace_map_items: bool = True):
        self.export_to = export_to
        self.trace_map_items = trace_map_items
        logfire.configure(send_to_logfire=(export_to == "cloud"))
    
    def on_pipeline_start(self, pipeline_id: str, inputs: Dict):
        """Create a new span for the pipeline execution"""
        self.pipeline_span = logfire.span(
            f"Pipeline: {pipeline_id}",
            pipeline_id=pipeline_id,
            inputs=self._sanitize_inputs(inputs)
        )
        self.pipeline_span.__enter__()
    
    def on_node_start(self, node_id: str, inputs: Dict):
        """Create a child span for node execution"""
        self.node_spans[node_id] = logfire.span(
            f"Node: {node_id}",
            node_id=node_id,
            inputs=self._sanitize_inputs(inputs)
        )
        self.node_spans[node_id].__enter__()
    
    def on_node_end(self, node_id: str, outputs: Dict, duration: float):
        """Close the node span with outputs and metrics"""
        span = self.node_spans[node_id]
        span.set_attribute("duration_ms", duration * 1000)
        span.set_attribute("outputs", self._sanitize_outputs(outputs))
        span.__exit__(None, None, None)
    
    def on_node_cached(self, node_id: str, signature: str):
        """Record cache hit in telemetry"""
        [logfire.info](http://logfire.info)(
            f"Cache hit: {node_id}",
            node_id=node_id,
            signature=signature,
            cache_hit=True
        )
    
    def on_nested_pipeline_start(self, parent_id: str, child_pipeline_id: str):
        """Create a nested span for child pipeline (recursive)"""
        self.nested_spans[child_pipeline_id] = logfire.span(
            f"Nested Pipeline: {child_pipeline_id}",
            parent_pipeline_id=parent_id,
            child_pipeline_id=child_pipeline_id
        )
        self.nested_spans[child_pipeline_id].__enter__()
    
    def on_error(self, node_id: str, error: Exception):
        """Record exception in span"""
        if node_id in self.node_spans:
            self.node_spans[node_id].record_exception(error)
            self.node_spans[node_id].__exit__(type(error), error, error.__traceback__)
```

---

# Hierarchical Tracing for Nested Pipelines

Logfire automatically maintains hierarchical span relationships for nested pipelines:

```python
# Nested pipeline example
inner_pipeline = Pipeline(
    functions=[preprocess, encode],
    backend=ModalBackend(gpu="A100")
)

outer_pipeline = Pipeline(
    functions=[load_data, inner_pipeline, aggregate],
    backend=LocalBackend(),
    callbacks=[LogfireCallback()]
)

result = outer_[pipeline.run](http://pipeline.run)(data=dataset)
```

**Logfire trace structure:**

```
outer_pipeline [48s]
├─ load_data [2s]
├─ inner_pipeline [43s] [Remote: Modal]
│  ├─ preprocess [8s]
│  └─ encode [35s] [GPU: A100]
└─ aggregate [3s]
```

**Key features:**

- Child spans are automatically nested within parent spans
- Remote execution context is propagated to Modal workers
- Backend and resource metadata (GPU type, etc.) attached to spans
- Cache hits are tracked at each level
- Errors in nested pipelines include full hierarchical context

---

# Context Propagation for Remote Execution

When a node executes on a remote backend (Modal, Coiled), Logfire context is serialized and transmitted:

## Serialization (Local → Remote)

```python
# In the backend's job dispatch logic
def dispatch_remote_job(node: Node, inputs: Dict):
    # Serialize active OpenTelemetry context
    from opentelemetry import context
    from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
    
    carrier = {}
    TraceContextTextMapPropagator().inject(carrier)
    
    # Send carrier along with job
    remote_function.remote(
        node=node,
        inputs=inputs,
        trace_context=carrier
    )
```

## Reattachment (Remote Worker)

```python
# On the remote worker (Modal, Coiled)
def execute_node_remote(node: Node, inputs: Dict, trace_context: Dict):
    # Reattach parent trace context
    from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
    
    ctx = TraceContextTextMapPropagator().extract(carrier=trace_context)
    
    # Execute node within restored context
    with logfire.span("Remote Node Execution", context=ctx):
        result = node.execute(inputs)
    
    return result
```

This ensures all remote telemetry is linked to the originating pipeline run.

---

# Live Visualization

## Waterfall Charts

Logfire's dashboard displays execution timelines with:

- Node dependencies and execution order
- Parallel execution visualization
- Cache hit indicators
- Remote vs. local execution boundaries
- Nested pipeline hierarchy

**Example visualization:**

- **Timeline view**: Shows when each node started/ended, with color-coding for status
- **Flamegraph view**: Hierarchical visualization of span durations
- **Metrics view**: Aggregated cache hit rates, throughput, error rates

## Notebook Integration

In Jupyter notebooks, Logfire provides:

- Live-updating progress widgets
- Interactive span inspection
- One-click navigation to full dashboard
- Collapsible nested pipeline views

```python
# Automatically renders live progress in notebook
with [logfire.live](http://logfire.live)_display():
    results = [pipeline.map](http://pipeline.map)(data=large_dataset)
```

## CLI Integration

For terminal execution, Logfire complements the built-in progress bars by:

- Streaming structured logs to console
- Providing a dashboard link for detailed inspection
- Optionally replacing progress bars with Logfire's rich terminal UI

---

# Map Operation Tracing

For [`pipeline.map](http://pipeline.map)()` operations, Logfire creates a hierarchical trace structure:

```
[pipeline.map](http://pipeline.map)(items) [120s]
├─ Item 0 [1.2s]
│  ├─ node_a [0.4s]
│  └─ node_b [0.8s]
├─ Item 1 [0.3s] [⚡ Cached]
├─ Item 2 [1.1s]
│  ├─ node_a [0.4s]
│  └─ node_b [0.7s]
└─ ...
```

**Configuration:**

- `trace_map_items=True`: Create individual spans per item (default for small batches)
- `trace_map_items=False`: Aggregate spans for large batches (reduces overhead)
- `sample_rate=0.1`: Sample 10% of items for detailed tracing

---

# Configuration Options

## Export Destinations

```python
# Send to Logfire cloud (default)
callback = LogfireCallback(export_to="cloud")

# Use local OpenTelemetry collector
callback = LogfireCallback(export_to="[localhost:4317](http://localhost:4317)")

# In-process only (no export, for testing)
callback = LogfireCallback(export_to=None)
```

## Sampling and Performance

```python
# Trace all executions
callback = LogfireCallback(sample_rate=1.0)

# Sample 10% (for high-throughput production workloads)
callback = LogfireCallback(sample_rate=0.1)

# Disable map item tracing (reduces span volume)
callback = LogfireCallback(trace_map_items=False)
```

## Custom Attributes

```python
# Add custom metadata to all spans
callback = LogfireCallback(
    custom_attributes={
        "environment": "production",
        "team": "ml-platform",
        "experiment_id": "exp-123"
    }
)
```

---

# Integration with Cache System

Logfire tracks caching behavior at multiple levels:

**Span attributes:**

- `cache_status`: "hit", "miss", "write"
- `cache_signature`: Computation signature
- `cache_duration_ms`: Time to retrieve from cache

**Metrics:**

- Cache hit rate per node
- Cache hit rate per pipeline
- Cache hit rate per map operation
- Storage savings (estimated compute time avoided)

**Example span:**

```
Node: encode_text [0.002s]
├─ cache_status: hit
├─ cache_signature: sha256:abc123...
├─ cache_duration_ms: 2
└─ compute_saved_ms: 15000 (estimated)
```

---

# Error Tracking and Debugging

When errors occur, Logfire captures:

- Full exception traceback
- Input values that caused the error
- Execution context (node, pipeline, backend)
- Related spans (parent pipeline, sibling nodes)
- Retry attempts (if applicable)

**Debugging workflow:**

1. View error in Logfire dashboard
2. Navigate to parent pipeline span for full context
3. Inspect input values that triggered the error
4. Check sibling node spans to isolate the issue
5. View logs and metrics for additional context

---

# Performance Overhead

**Typical overhead:**

- **Local execution**: <1% (span creation/closure)
- **Remote execution**: <2% (context serialization)
- **Map operations with item tracing**: 1-3% depending on item count
- **High-cardinality attributes**: 2-5% (input/output serialization)

**Optimization strategies:**

- Use sampling for high-throughput workloads
- Disable map item tracing for large batches
- Sanitize large inputs/outputs before attaching to spans
- Use async exporters to avoid blocking execution

---

# Example: Complete Integration

```python
from pipeline_system import Pipeline, LogfireCallback, func

# Define pipeline functions
@func(output="cleaned")
def clean(text: str) -> str:
    return text.strip().lower()

@func(output="encoded")
def encode(cleaned: str, model: Encoder) -> Vector:
    return model.encode(cleaned)

# Create nested pipeline
preprocessing = Pipeline(functions=[clean])

main_pipeline = Pipeline(
    functions=[preprocessing, encode],
    callbacks=[LogfireCallback(
        export_to="cloud",
        custom_attributes={"experiment": "v1.2"}
    )]
)

# Single execution with live tracing
result = main_[pipeline.run](http://pipeline.run)(text="Hello World", model=encoder)

# Batch execution with hierarchical tracing
results = main_[pipeline.map](http://pipeline.map)(
    data=[{"text": t} for t in texts],
    model=encoder
)
```

**View traces:**

- Dashboard: [`https://logfire.pydantic.dev/project/your-project`](https://logfire.pydantic.dev/project/your-project)
- Or use `logfire.print_dashboard_url()` to get the link

---

# Best Practices

1. **Always enable in production**: Telemetry overhead is minimal and invaluable for debugging
2. **Use custom attributes**: Tag spans with experiment IDs, model versions, etc.
3. **Monitor cache hit rates**: Low rates indicate caching strategy issues
4. **Leverage nested pipeline tracing**: Hierarchical views reveal bottlenecks
5. **Export to persistent storage**: Cloud export or local collector for historical analysis
6. **Sample high-throughput workloads**: Reduce overhead while maintaining observability
7. **Sanitize sensitive data**: Remove PII from span attributes before export

---

# References

- Logfire Documentation: [https://logfire.pydantic.dev/](https://logfire.pydantic.dev/)
- OpenTelemetry Python: [https://opentelemetry.io/docs/instrumentation/python/](https://opentelemetry.io/docs/instrumentation/python/)
- [Tracing & Telemetry](../Tracing%20&%20Telemetry%20da0bddf3d656448e99f2b968fd8c2b49.md)
- [Intelligent Callback System](../Intelligent%20Callback%20System%20be7cb6cd6a5f419fb949210a31497a73.md)
- [Backends](../Backends%207ba2913775254dec81a496ec0e3a27e5.md)
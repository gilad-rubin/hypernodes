{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from hypster import HP, config\n",
                "\n",
                "\n",
                "@config\n",
                "def hp_config(hp: HP):\n",
                "    from hypernodes import NodeRegistry\n",
                "    from hypernodes.mlflow_utils import (\n",
                "        EnvironmentGenerator,\n",
                "        HyperNodeMLFlow,\n",
                "        MLFlowSetup,\n",
                "        get_existing_dependencies_files,\n",
                "    )\n",
                "\n",
                "    registry = NodeRegistry.initialize()\n",
                "    nodes = registry.list_nodes(require_hamilton_dags=True, require_hypster_config=True)\n",
                "    if len(nodes) == 0:\n",
                "        raise ValueError(\"No nodes found in registry\")\n",
                "\n",
                "    node_name = hp.select(nodes, default=nodes[0])\n",
                "    node = registry.load(node_name)\n",
                "\n",
                "    node_configs = hp.propagate(node.hypster_config, name=f\"{node_name}_inputs\")\n",
                "    node.set_instantiated_config(node_configs)\n",
                "\n",
                "    available_vars = [n.name for n in node._driver.list_available_variables()]\n",
                "    if len(available_vars) == 0:\n",
                "        raise ValueError(\"No available variables found\")\n",
                "\n",
                "    dynamic_inputs = []\n",
                "    for var in available_vars:\n",
                "        include_var = hp.select([False, True], default=False, name=f\"{var}_is_input\")\n",
                "        if include_var:\n",
                "            dynamic_inputs.append(var)\n",
                "\n",
                "    final_vars = []\n",
                "    for var in available_vars:\n",
                "        include_var = hp.select([False, True], default=False, name=f\"{var}_is_output\")\n",
                "        if include_var:\n",
                "            final_vars.append(var)\n",
                "\n",
                "    env_name = hp.text(f\"{node_name}_env\")\n",
                "    dependencies_files = get_existing_dependencies_files()  # TODO: find project root\n",
                "    if len(dependencies_files) == 0:\n",
                "        dependency_file = hp.text()\n",
                "    else:\n",
                "        dependency_file = hp.select(dependencies_files, default=dependencies_files[0])\n",
                "\n",
                "    extra_dependencies = hp.text(\"\")  # multi_text\n",
                "    from hypernodes.mlflow_utils import EnvironmentGenerator\n",
                "\n",
                "    sys_python_version = EnvironmentGenerator.detect_python_version()\n",
                "    python_version = hp.text(sys_python_version)\n",
                "    conda_env = EnvironmentGenerator(\n",
                "        env_name=f\"{node_name}-env\",\n",
                "        dependency_file=dependency_file,\n",
                "        extra_dependencies=extra_dependencies,\n",
                "        python_version=python_version,\n",
                "    ).to_conda()\n",
                "\n",
                "    code_paths = [\"src\"]\n",
                "    dotenv_file = \".env\"\n",
                "    mlflow_setup = MLFlowSetup(\n",
                "        registry=registry,\n",
                "        artifacts={},\n",
                "        dotenv_file=dotenv_file,\n",
                "        code_paths=code_paths,\n",
                "        conda_env=conda_env,\n",
                "    )  # example_input=, signature=\n",
                "\n",
                "    values = {\n",
                "        k.replace(f\"{node_name}.\", \"\"): v\n",
                "        for k, v in hp.values.items()\n",
                "        if k.startswith(f\"{node_name}.\")\n",
                "    }\n",
                "\n",
                "    model = HyperNodeMLFlow(\n",
                "        node_name=node_name,\n",
                "        dynamic_inputs=dynamic_inputs,\n",
                "        final_vars=final_vars,\n",
                "        values=values,\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "values = {\n",
                "    \"node_name\": \"parent_node\",\n",
                "    \"input_is_input\": True,\n",
                "    \"downstream_is_output\": True,\n",
                "    \"parent_node.basic_usage.llm_model\": \"haiku\",\n",
                "    \"dependency_file\": \"requirements.txt\",\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs = hp_config(final_vars=[\"model\", \"mlflow_setup\"], values=values)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Log & Register Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7863151c27ea4c8f83f967442e4f4938",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b25ffb1b5533400d980b60d2f788700c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "85e212db9da041a8a7a9d87eb6f08cd2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4feafe287913434183922f016cbe09c5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e9d9c0777c0c44a3b52e5787378af69d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024/10/08 09:40:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
                        "Registered model 'hypernodes_model' already exists. Creating a new version of this model...\n",
                        "Created version '63' of model 'hypernodes_model'.\n"
                    ]
                }
            ],
            "source": [
                "mlflow_setup = inputs[\"mlflow_setup\"]\n",
                "model_uri = mlflow_setup.log_model(inputs[\"model\"])\n",
                "model_reg = mlflow_setup.register_model(model_uri, \"hypernodes_model\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Locally"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'node_registry_path': 'node_registry_updated.yaml', 'registry': <hypernodes.registry.NodeRegistry object at 0x1759af610>, 'nested_node': <hypernodes.hypernode.HyperNode object at 0x1759af430>, 'basic_usage_inputs': {'data_path': 'data', 'env': 'dev', 'llm_model': 'claude-3-haiku-20240307'}, 'downstream_node': <hypernodes.hypernode.HyperNode object at 0x1759adf60>, 'input': 'testing'}\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "model = mlflow_setup.load_model(model_uri)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "example = pd.DataFrame({\"input\": [\"hey\"]}, index=[0])\n",
                "result = model.predict(example)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Querying claude-3-haiku-20240307... hey'"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hypernodes-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

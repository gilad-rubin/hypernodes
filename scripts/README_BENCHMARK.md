# HyperNodes vs Daft Comprehensive Benchmark

## Overview

This benchmark suite provides a comprehensive comparison between **HyperNodes** and **Daft** across multiple real-world scenarios. The goal is to help you understand when to use each framework and what performance characteristics to expect.

## Files

- **`benchmark_hypernodes_vs_daft.py`** - Main benchmark script
- **`BENCHMARK_RESULTS.md`** - Detailed results and analysis
- **`README_BENCHMARK.md`** - This file

## Quick Start

```bash
cd /Users/giladrubin/python_workspace/hypernodes
uv run python scripts/benchmark_hypernodes_vs_daft.py
```

## Benchmark Scenarios

### 1. Simple Text Processing
Tests basic data transformations: cleaning, tokenizing, and counting tokens.

**Implementations:**
- HyperNodes: Sequential pipeline with 3 nodes
- Daft UDF: Custom functions with `@daft.func`
- Daft Built-in: Native `.str.split()` and `.list.length()`

**Key Insight:** Daft's built-in operations are 13x faster than HyperNodes sequential mode.

### 2. Stateful Processing with Expensive Initialization
Simulates loading a model with expensive initialization (0.1s sleep).

**Implementations:**
- HyperNodes: Pre-initialized encoder passed to pipeline
- Daft UDF: `@daft.cls` for lazy initialization per worker

**Key Insight:** HyperNodes is 3.7x faster when you have pre-initialized objects.

### 3. Batch Vectorized Operations
Tests numerical operations that benefit from vectorization.

**Implementations:**
- HyperNodes: Row-wise processing with threaded execution
- Daft Batch UDF: `@daft.func.batch` with PyArrow
- Daft Built-in: Native arithmetic operations

**Key Insight:** Daft's built-in operations are 15x faster than HyperNodes threaded mode.

### 4. Nested Pipelines with Heavy Computation
Simulates a retrieval pipeline: encode documents, then search for each query.

**Implementations:**
- HyperNodes: Nested pipelines with explicit control
- Daft UDF: Chained DataFrame operations

**Key Insight:** Daft's automatic optimization makes it 35% faster for complex workflows.

### 5. Generator Functions (One-to-Many)
Tests expanding each input into multiple outputs (tokenization).

**Implementations:**
- HyperNodes: Manual flattening after pipeline execution
- Daft Generator UDF: `@daft.func` with `Iterator[T]` return type
- Daft Built-in: `.str.split()` + `.explode()`

**Key Insight:** Daft's native generator support is 2x faster than manual flattening.

## Configuration

### Scale Factors

The benchmark supports three scale factors (modify `CURRENT_SCALE` in the script):

```python
SCALE_FACTORS = {
    "small": 100,      # Quick test
    "medium": 1000,    # Default
    "large": 5000,     # Stress test
}
```

### HyperNodes Execution Modes

Test different execution strategies by modifying the backend:

```python
# Sequential (default)
backend = LocalBackend(node_execution="sequential", map_execution="sequential")

# Threaded (I/O + CPU)
backend = LocalBackend(node_execution="threaded", map_execution="threaded")

# Async (I/O-bound)
backend = LocalBackend(node_execution="async", map_execution="async")

# Parallel (CPU-bound, requires picklable objects)
backend = LocalBackend(node_execution="parallel", map_execution="parallel")
```

## Results Summary (Medium Scale: 1000 items)

| Benchmark | HyperNodes | Daft UDF | Daft Built-in | Winner |
|-----------|-----------|----------|---------------|--------|
| 1. Text Processing | 0.1486s | 0.6000s | **0.0715s** | Daft Built-in |
| 2. Stateful Processing | **0.0299s** | 0.1095s | N/A | HyperNodes |
| 3. Batch Operations | 0.1393s | 0.1120s | **0.0085s** | Daft Built-in |
| 4. Nested Pipelines | 0.3706s | **0.2398s** | N/A | Daft UDF |
| 5. Generators | 0.0432s | 0.0292s | **0.0198s** | Daft Built-in |

## Key Findings

### Performance

1. **Daft Built-ins are Fastest**: When available, Daft's native operations are significantly faster (8-16x speedup)
2. **HyperNodes Excels with Pre-initialized Objects**: 3.7x faster when working with expensive objects initialized upfront
3. **Daft's Automatic Optimization Wins**: For complex workflows, Daft's optimizer provides 35% speedup
4. **Vectorized Operations**: Daft's batch processing shows dramatic improvements for numerical data

### Design Philosophy

**HyperNodes:**
- âœ… Explicit control over execution flow
- âœ… Fine-grained caching at node level
- âœ… Multiple execution modes (sequential, threaded, async, parallel)
- âœ… Excellent for modular, reusable components
- âœ… Great for ML pipelines with complex logic

**Daft:**
- âœ… Automatic parallelization and optimization
- âœ… Built-in operations are highly optimized
- âœ… Lazy evaluation with query planning
- âœ… Excellent for large-scale data processing
- âœ… Great for vectorized operations

## When to Use Each

### Use HyperNodes When:
- ðŸŽ¯ You need explicit DAG visualization and control
- ðŸŽ¯ You want fine-grained caching with explicit cache keys
- ðŸŽ¯ You have expensive objects initialized upfront
- ðŸŽ¯ You're building modular, reusable pipeline components
- ðŸŽ¯ You need complex branching logic
- ðŸŽ¯ You want to switch between execution modes easily

### Use Daft When:
- ðŸš€ Performance is critical
- ðŸš€ You're processing large datasets (>1GB)
- ðŸš€ You want automatic optimization
- ðŸš€ You need distributed execution
- ðŸš€ Your operations can be vectorized
- ðŸš€ You can use Daft's built-in operations

### Hybrid Approach:
Consider using both frameworks together:
- **HyperNodes** for high-level orchestration and complex logic
- **Daft** for data-intensive processing steps

## Extending the Benchmark

### Adding New Scenarios

1. Define your test data
2. Implement HyperNodes version
3. Implement Daft UDF version
4. Implement Daft built-in version (if possible)
5. Add timing and comparison logic
6. Update the summary section

Example structure:

```python
# ==================== Benchmark N: Your Scenario ====================
print("\n" + "=" * 80)
print("BENCHMARK N: Your Scenario Description")
print("=" * 80)

# Generate test data
test_data = [...]

# --- HyperNodes Version ---
@node(output_name="result")
def process_hn(input: Type) -> Type:
    return ...

pipeline_hn = Pipeline(nodes=[process_hn], name="your_scenario")
backend = LocalBackend(node_execution="sequential")
pipeline_hn = pipeline_hn.with_backend(backend)

start = time.perf_counter()
results_hn = pipeline_hn.map(inputs={"input": test_data}, map_over="input")
elapsed_hn = time.perf_counter() - start
print(f"HyperNodes: {elapsed_hn:.4f}s")

# --- Daft UDF Version ---
@daft.func
def process_daft(input: Type) -> Type:
    return ...

df_daft = daft.from_pydict({"input": test_data})
start = time.perf_counter()
df_daft = df_daft.with_column("result", process_daft(df_daft["input"]))
results_daft = df_daft.collect()
elapsed_daft = time.perf_counter() - start
print(f"Daft (UDF): {elapsed_daft:.4f}s")

# --- Daft Built-in Version (if applicable) ---
# ...

print(f"\nResults verified: ...")
```

## Testing Different Scales

To test performance at different scales:

```bash
# Edit the script and change CURRENT_SCALE
# Then run:
uv run python scripts/benchmark_hypernodes_vs_daft.py
```

Expected behavior:
- **Small (100 items)**: Quick sanity check
- **Medium (1000 items)**: Default, good balance
- **Large (5000 items)**: Stress test, shows scaling characteristics

## Dependencies

The benchmark requires:
- `hypernodes` - The HyperNodes framework
- `daft` - The Daft dataframe library
- `numpy` - For numerical operations
- `pydantic` - For data models

Install with:
```bash
uv pip install hypernodes daft numpy pydantic
```

## Interpreting Results

### Timing Considerations

1. **First Run**: May include JIT compilation overhead
2. **Caching**: HyperNodes caching is disabled in benchmarks for fair comparison
3. **Parallelization**: Daft automatically parallelizes, HyperNodes requires explicit configuration
4. **Memory**: Not measured in current benchmarks, but important for large datasets

### Performance Factors

- **Data Size**: Larger datasets favor Daft's optimizations
- **Operation Type**: Vectorizable operations favor Daft built-ins
- **Initialization Cost**: Pre-initialized objects favor HyperNodes
- **Complexity**: Complex workflows favor Daft's automatic optimization

## Contributing

To add new benchmarks or improve existing ones:

1. Follow the existing structure
2. Test with all three scale factors
3. Document your findings
4. Update this README and BENCHMARK_RESULTS.md

## Related Resources

- [HyperNodes Documentation](../docs/)
- [Daft Documentation](https://www.getdaft.io/)
- [HyperNodes to Daft Translation Guide](../notebooks/DAFT_TRANSLATION_GUIDE.md)
- [Daft UDF Guide](../guides/daft-udfs.md)

## License

Same as the HyperNodes project.

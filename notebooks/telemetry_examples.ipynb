{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperNodes Telemetry & Observability Examples\n",
    "\n",
    "This notebook demonstrates the telemetry and observability features of HyperNodes:\n",
    "- **ProgressCallback**: Live progress bars\n",
    "- **TelemetryCallback**: Distributed tracing with Logfire\n",
    "- **Waterfall Charts**: Post-hoc analysis\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure you have the telemetry dependencies installed:\n",
    "```bash\n",
    "pip install 'hypernodes[telemetry]'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<logfire._internal.main.Logfire at 0x103efb440>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import logfire\n",
    "from hypernodes import node, Pipeline\n",
    "from hypernodes.telemetry import ProgressCallback, TelemetryCallback\n",
    "\n",
    "# Configure logfire (local only, no cloud export)\n",
    "logfire.configure(send_to_logfire=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Pipeline with Progress\n",
    "\n",
    "Simple pipeline showing live progress bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0729233ca84fcd9360a34b8cfa4d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ double âœ“ (0.51s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ double âœ“ (0.51s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ add_one âœ“ (0.31s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ add_one âœ“ (0.31s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: {'doubled': 10, 'result': 11}\n"
     ]
    }
   ],
   "source": [
    "@node(output_name=\"doubled\")\n",
    "def double(x: int) -> int:\n",
    "    \"\"\"Double the input value.\"\"\"\n",
    "    time.sleep(0.5)  # Simulate work\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def add_one(doubled: int) -> int:\n",
    "    \"\"\"Add one to the value.\"\"\"\n",
    "    time.sleep(0.3)  # Simulate work\n",
    "    return doubled + 1\n",
    "\n",
    "\n",
    "# Create pipeline with progress callback\n",
    "pipeline = Pipeline(nodes=[double, add_one], callbacks=[ProgressCallback()])\n",
    "\n",
    "result = pipeline.run(inputs={\"x\": 5})\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Progress + Telemetry Together\n",
    "\n",
    "Combine progress bars with telemetry tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6859af9faadf41b0a57188a5482b8d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:47.315 pipeline:pipeline_4478218752\n",
      "11:36:47.319   node:preprocess\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ preprocess âœ“ (0.21s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ preprocess âœ“ (0.21s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:47.527   node:tokenize\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ tokenize âœ“ (0.30s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ tokenize âœ“ (0.30s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ count_tokens âœ“ (0.11s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ count_tokens âœ“ (0.11s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:47.835   node:count_tokens\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: {'preprocessed': 'hello world from hypernodes!', 'tokens': ['hello', 'world', 'from', 'hypernodes!'], 'count': 4}\n"
     ]
    }
   ],
   "source": [
    "@node(output_name=\"preprocessed\")\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"Clean and preprocess text.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "@node(output_name=\"tokens\")\n",
    "def tokenize(preprocessed: str) -> list:\n",
    "    \"\"\"Split text into tokens.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return preprocessed.split()\n",
    "\n",
    "\n",
    "@node(output_name=\"count\")\n",
    "def count_tokens(tokens: list) -> int:\n",
    "    \"\"\"Count the tokens.\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "# Create callbacks\n",
    "progress = ProgressCallback()\n",
    "telemetry = TelemetryCallback()\n",
    "\n",
    "# Compose them\n",
    "pipeline = Pipeline(\n",
    "    nodes=[preprocess, tokenize, count_tokens], callbacks=[progress, telemetry]\n",
    ")\n",
    "\n",
    "result = pipeline.run(inputs={\"text\": \"  Hello World from HyperNodes!  \"})\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Waterfall Chart Visualization\n",
    "\n",
    "Generate an interactive waterfall chart showing execution timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a63b60b708411ea0b04978ecb326cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:47.957 pipeline:main_pipeline\n",
      "11:36:47.960   node:load_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ load_data âœ“ (0.10s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ load_data âœ“ (0.10s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:48.578   node:aggregate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ aggregate âœ“ (0.21s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ aggregate âœ“ (0.21s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result: {'data': '  DATA FROM database  ', 'cleaned': 'DATA FROM database', 'normalized': 'data from database', 'final_result': {'processed': 'data from database', 'length': 18}}\n"
     ]
    }
   ],
   "source": [
    "# Define inner pipeline nodes\n",
    "@node(output_name=\"cleaned\")\n",
    "def clean_data(data: str) -> str:  # Changed from 'raw' to 'data'\n",
    "    \"\"\"Clean the raw data.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return data.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized\")\n",
    "def normalize(cleaned: str) -> str:\n",
    "    \"\"\"Normalize the data.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return cleaned.lower()\n",
    "\n",
    "\n",
    "# Create inner pipeline\n",
    "inner_pipeline = Pipeline(nodes=[clean_data, normalize], id=\"preprocessing\")\n",
    "\n",
    "\n",
    "# Define outer pipeline nodes\n",
    "@node(output_name=\"data\")\n",
    "def load_data(source: str) -> str:\n",
    "    \"\"\"Load data from source.\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return f\"  DATA FROM {source}  \"\n",
    "\n",
    "\n",
    "@node(output_name=\"final_result\")\n",
    "def aggregate(normalized: str) -> dict:\n",
    "    \"\"\"Aggregate the results.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return {\"processed\": normalized, \"length\": len(normalized)}\n",
    "\n",
    "\n",
    "# Create outer pipeline\n",
    "telemetry_nested = TelemetryCallback()\n",
    "\n",
    "outer_pipeline = Pipeline(\n",
    "    nodes=[load_data, inner_pipeline, aggregate],\n",
    "    callbacks=[ProgressCallback(), telemetry_nested],\n",
    "    id=\"main_pipeline\",\n",
    ")\n",
    "\n",
    "result = outer_pipeline.run(inputs={\"source\": \"database\"})\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Nested Pipelines\n",
    "\n",
    "Demonstrate hierarchical progress and tracing with nested pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4c7326d60147dc913e264ea70b7ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    â”œâ”€ load_data âœ“ (0.11s): <span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    â”œâ”€ load_data âœ“ (0.11s): \u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:36:48.806 pipeline:main_pipeline\n",
      "11:36:48.809   node:load_data\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     36\u001b[39m telemetry_nested = TelemetryCallback()\n\u001b[32m     38\u001b[39m outer_pipeline = Pipeline(\n\u001b[32m     39\u001b[39m     nodes=[load_data, inner_pipeline, aggregate],\n\u001b[32m     40\u001b[39m     callbacks=[ProgressCallback(), telemetry_nested],\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mmain_pipeline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m result = \u001b[43mouter_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatabase\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/pipeline.py:396\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, inputs, _ctx)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;66;03m# Use effective backend to support inheritance\u001b[39;00m\n\u001b[32m    395\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.effective_backend\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/backend.py:117\u001b[39m, in \u001b[36mLocalBackend.run\u001b[39m\u001b[34m(self, pipeline, inputs, ctx)\u001b[39m\n\u001b[32m    113\u001b[39m     callback.on_nested_pipeline_start(pipeline.id, node.id, ctx)\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Nested pipeline - delegate to its effective backend\u001b[39;00m\n\u001b[32m    116\u001b[39m nested_inputs = {\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     k: \u001b[43mavailable_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node.root_args\n\u001b[32m    119\u001b[39m }\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# Use effective_backend for configuration inheritance\u001b[39;00m\n\u001b[32m    121\u001b[39m nested_backend = node.effective_backend \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(node, \u001b[33m'\u001b[39m\u001b[33meffective_backend\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (node.backend \u001b[38;5;129;01mor\u001b[39;00m LocalBackend())\n",
      "\u001b[31mKeyError\u001b[39m: 'raw'"
     ]
    }
   ],
   "source": [
    "# Define inner pipeline nodes\n",
    "@node(output_name=\"cleaned\")\n",
    "def clean_data(raw: str) -> str:\n",
    "    \"\"\"Clean the raw data.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return raw.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized\")\n",
    "def normalize(cleaned: str) -> str:\n",
    "    \"\"\"Normalize the data.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return cleaned.lower()\n",
    "\n",
    "\n",
    "# Create inner pipeline\n",
    "inner_pipeline = Pipeline(nodes=[clean_data, normalize], id=\"preprocessing\")\n",
    "\n",
    "\n",
    "# Define outer pipeline nodes\n",
    "@node(output_name=\"data\")\n",
    "def load_data(source: str) -> str:\n",
    "    \"\"\"Load data from source.\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return f\"  DATA FROM {source}  \"\n",
    "\n",
    "\n",
    "@node(output_name=\"final_result\")\n",
    "def aggregate(normalized: str) -> dict:\n",
    "    \"\"\"Aggregate the results.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return {\"processed\": normalized, \"length\": len(normalized)}\n",
    "\n",
    "\n",
    "# Create outer pipeline\n",
    "telemetry_nested = TelemetryCallback()\n",
    "\n",
    "outer_pipeline = Pipeline(\n",
    "    nodes=[load_data, inner_pipeline, aggregate],\n",
    "    callbacks=[ProgressCallback(), telemetry_nested],\n",
    "    id=\"main_pipeline\",\n",
    ")\n",
    "\n",
    "result = outer_pipeline.run(inputs={\"source\": \"database\"})\n",
    "print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Pipeline Waterfall Chart\n",
    "\n",
    "Notice how the chart shows the hierarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = telemetry_nested.get_waterfall_chart()\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Map Operations\n",
    "\n",
    "Process multiple items with progress tracking and telemetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Process multiple items\u001b[39;00m\n\u001b[32m     23\u001b[39m items = [{\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: i} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m21\u001b[39m)]  \u001b[38;5;66;03m# 20 items\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m results = \u001b[43mmap_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_over\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m items\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[:\u001b[32m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/pipeline.py:556\u001b[39m, in \u001b[36mmap\u001b[39m\u001b[34m(self, inputs, map_over, map_mode)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mas_node\u001b[39m(\n\u001b[32m    525\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    526\u001b[39m     input_mapping: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    527\u001b[39m     output_mapping: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    528\u001b[39m     map_over: Optional[Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    529\u001b[39m ) -> PipelineNode:\n\u001b[32m    530\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrap this pipeline as a node with custom input/output mapping.\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    532\u001b[39m \u001b[33;03m    This method allows a pipeline to be used as a node in another pipeline\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[33;03m    with renamed parameters and/or internal mapping over collections.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[33;03m        input_mapping: Maps outer parameter names to inner names.\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[33;03m                      Format: {outer_name: inner_name}\u001b[39;00m\n\u001b[32m    538\u001b[39m \u001b[33;03m                      Direction: outer â†’ inner (how inputs flow IN)\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[33;03m        output_mapping: Maps inner output names to outer names.\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[33;03m                       Format: {inner_name: outer_name}\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[33;03m                       Direction: inner â†’ outer (how outputs flow OUT)\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m        map_over: Parameter name(s) that should be mapped over.\u001b[39;00m\n\u001b[32m    543\u001b[39m \u001b[33;03m                 From outer pipeline's perspective, this is a list parameter.\u001b[39;00m\n\u001b[32m    544\u001b[39m \u001b[33;03m                 Internally, the pipeline maps over each item.\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[33;03m        PipelineNode that wraps this pipeline with the specified mapping\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[33;03m        >>> inner = Pipeline(nodes=[clean_text])  # expects \"passage\"\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m        >>> adapted = inner.as_node(\u001b[39;00m\n\u001b[32m    552\u001b[39m \u001b[33;03m        ...     input_mapping={\"document\": \"passage\"},  # outer -> inner\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[33;03m        ...     output_mapping={\"cleaned\": \"processed\"}  # inner -> outer\u001b[39;00m\n\u001b[32m    554\u001b[39m \u001b[33;03m        ... )\u001b[39;00m\n\u001b[32m    555\u001b[39m \u001b[33;03m        >>> outer = Pipeline(nodes=[adapted])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m \u001b[33;03m        >>> result = outer.run(inputs={\"document\": \"text\"})\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[33;03m        >>> # result[\"processed\"] contains the cleaned text\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PipelineNode(\n\u001b[32m    560\u001b[39m         pipeline=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    561\u001b[39m         input_mapping=input_mapping,\n\u001b[32m    562\u001b[39m         output_mapping=output_mapping,\n\u001b[32m    563\u001b[39m         map_over=map_over,\n\u001b[32m    564\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "@node(output_name=\"squared\")\n",
    "def square(x: int) -> int:\n",
    "    \"\"\"Square a number.\"\"\"\n",
    "    time.sleep(0.1)  # Simulate processing\n",
    "    return x * x\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def is_even(squared: int) -> bool:\n",
    "    \"\"\"Check if squared result is even.\"\"\"\n",
    "    time.sleep(0.05)\n",
    "    return squared % 2 == 0\n",
    "\n",
    "\n",
    "# Create pipeline for mapping\n",
    "telemetry_map = TelemetryCallback(trace_map_items=False)  # Don't trace each item\n",
    "\n",
    "map_pipeline = Pipeline(\n",
    "    nodes=[square, is_even], callbacks=[ProgressCallback(), telemetry_map]\n",
    ")\n",
    "\n",
    "# Process multiple items\n",
    "items = [{\"x\": i} for i in range(1, 21)]  # 20 items\n",
    "results = map_pipeline.map(inputs=items, map_over=\"x\")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} items\")\n",
    "print(f\"Sample results: {results[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Testing with Disabled Progress\n",
    "\n",
    "For automated testing, you can disable progress bars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"result\")\n",
    "def simple_task(x: int) -> int:\n",
    "    \"\"\"Simple computation.\"\"\"\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "# Disabled progress (useful for tests)\n",
    "progress_disabled = ProgressCallback(enable=False)\n",
    "\n",
    "test_pipeline = Pipeline(nodes=[simple_task], callbacks=[progress_disabled])\n",
    "\n",
    "result = test_pipeline.run(inputs={\"x\": 10})\n",
    "print(f\"Result (no progress shown): {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Complex Pipeline with Multiple Stages\n",
    "\n",
    "A more realistic example with multiple processing stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"loaded\")\n",
    "def load_text(filename: str) -> str:\n",
    "    \"\"\"Simulate loading text from file.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return f\"Sample text from {filename}\"\n",
    "\n",
    "\n",
    "@node(output_name=\"cleaned\")\n",
    "def clean_text(loaded: str) -> str:\n",
    "    \"\"\"Clean the text.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return loaded.lower().strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"tokens\")\n",
    "def extract_tokens(cleaned: str) -> list:\n",
    "    \"\"\"Extract tokens.\"\"\"\n",
    "    time.sleep(0.4)\n",
    "    return cleaned.split()\n",
    "\n",
    "\n",
    "@node(output_name=\"features\")\n",
    "def extract_features(tokens: list) -> dict:\n",
    "    \"\"\"Extract features from tokens.\"\"\"\n",
    "    time.sleep(0.5)\n",
    "    return {\n",
    "        \"token_count\": len(tokens),\n",
    "        \"unique_tokens\": len(set(tokens)),\n",
    "        \"avg_length\": sum(len(t) for t in tokens) / len(tokens) if tokens else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "@node(output_name=\"analysis\")\n",
    "def analyze(features: dict) -> dict:\n",
    "    \"\"\"Analyze the features.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return {\n",
    "        **features,\n",
    "        \"complexity_score\": features[\"unique_tokens\"] / features[\"token_count\"]\n",
    "        if features[\"token_count\"] > 0\n",
    "        else 0,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create complex pipeline\n",
    "telemetry_complex = TelemetryCallback()\n",
    "\n",
    "complex_pipeline = Pipeline(\n",
    "    nodes=[load_text, clean_text, extract_tokens, extract_features, analyze],\n",
    "    callbacks=[ProgressCallback(), telemetry_complex],\n",
    "    name=\"text_analysis\",\n",
    ")\n",
    "\n",
    "result = complex_pipeline.run(inputs={\"filename\": \"document.txt\"})\n",
    "print(f\"\\nAnalysis Result:\")\n",
    "for key, value in result.items():\n",
    "    if key == \"analysis\":\n",
    "        print(f\"  {key}:\")\n",
    "        for k, v in value.items():\n",
    "            print(f\"    {k}: {v:.3f}\" if isinstance(v, float) else f\"    {k}: {v}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Pipeline Waterfall\n",
    "\n",
    "Visualize the execution flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = telemetry_complex.get_waterfall_chart()\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart Legend\n",
    "\n",
    "**Waterfall Chart Colors:**\n",
    "- ğŸŸ¦ **Blue**: Regular nodes\n",
    "- ğŸŸ§ **Orange**: Pipelines\n",
    "- ğŸŸ© **Green**: Cached operations or map operations\n",
    "\n",
    "**Features:**\n",
    "- Hover over bars to see details (duration, depth, type)\n",
    "- Bars are arranged hierarchically (parent pipelines above children)\n",
    "- Timeline shows parallel execution where applicable\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. âœ… **ProgressCallback** - Live progress bars with hierarchical display\n",
    "2. âœ… **TelemetryCallback** - Distributed tracing with Logfire\n",
    "3. âœ… **Waterfall Charts** - Interactive post-hoc analysis\n",
    "4. âœ… **Nested Pipelines** - Automatic hierarchy handling\n",
    "5. âœ… **Map Operations** - Batch processing with progress\n",
    "6. âœ… **Testing Mode** - Disabling progress for automation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- ğŸ“– Read the full guide: `docs/guides/TELEMETRY_GUIDE.md`\n",
    "- ğŸ”— Set up Logfire cloud: https://logfire.pydantic.dev\n",
    "- ğŸ§ª Run tests: `pytest tests/test_telemetry_*`\n",
    "- ğŸ“Š Experiment with your own pipelines!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

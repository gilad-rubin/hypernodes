{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Protocol, Sequence, Tuple, TypedDict\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "from hypernodes import Pipeline, node\n",
    "\n",
    "# ---- Core vector type -------------------------------------------------------\n",
    "Vector = npt.NDArray[np.float32]\n",
    "\n",
    "\n",
    "# ---- Protocols -------------------------------------------------------------\n",
    "class Encoder(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def encode(self, text: str, is_query: bool = False) -> Vector: ...\n",
    "\n",
    "\n",
    "class Indexer(Protocol):\n",
    "    def index(self, encoded: Sequence[EncodedPassage]) -> BaseIndex: ...\n",
    "\n",
    "\n",
    "class Reranker(Protocol):\n",
    "    def rerank(\n",
    "        self, query: Query, hits: Sequence[RetrievedDoc], top_k: Optional[int] = None\n",
    "    ) -> List[RetrievedDoc]: ...\n",
    "\n",
    "\n",
    "# ---- Data models ------------------------------------------------------------\n",
    "@dataclass(frozen=True)\n",
    "class Passage:\n",
    "    pid: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EncodedPassage:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Query:\n",
    "    text: str\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RetrievedDoc:\n",
    "    pid: str\n",
    "    text: str\n",
    "    embedding: Vector\n",
    "    score: float\n",
    "\n",
    "\n",
    "class SearchHit(TypedDict):\n",
    "    pid: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class BaseIndex(Protocol):\n",
    "    dim: int\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None: ...\n",
    "\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]: ...\n",
    "\n",
    "    def get(self, pid: str) -> EncodedPassage: ...\n",
    "\n",
    "\n",
    "# ---- Implementations -------------------------------------------------------\n",
    "class NumpyRandomEncoder:\n",
    "    def __init__(self, dim: int = 4, seed: int = 42):\n",
    "        self.dim = dim\n",
    "        self.seed = seed  # Public attribute, included in cache key\n",
    "\n",
    "    def encode(self, text: str, is_query: bool = False) -> Vector:\n",
    "        # Recreate RNG with seed for determinism\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        return rng.random(self.dim, dtype=np.float32)\n",
    "\n",
    "\n",
    "class InMemoryIndex:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "        self._data: Dict[str, EncodedPassage] = {}\n",
    "\n",
    "    def add(self, items: Sequence[EncodedPassage]) -> None:\n",
    "        for it in items:\n",
    "            self._data[it.pid] = it\n",
    "\n",
    "    def search(self, query_vec: Vector, top_k: int = 10) -> List[SearchHit]:\n",
    "        q = query_vec / (np.linalg.norm(query_vec) + 1e-12)\n",
    "        hits: List[Tuple[str, float]] = []\n",
    "        for pid, ep in self._data.items():\n",
    "            v = ep.embedding / (np.linalg.norm(ep.embedding) + 1e-12)\n",
    "            hits.append((pid, float(np.dot(q, v))))\n",
    "        hits.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [{\"pid\": pid, \"score\": score} for pid, score in hits[:top_k]]\n",
    "\n",
    "    def get(self, pid: str) -> EncodedPassage:\n",
    "        return self._data[pid]\n",
    "\n",
    "\n",
    "class SimpleIndexer:\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        self.dim = dim\n",
    "\n",
    "    def index(self, encoded: Sequence[EncodedPassage]) -> BaseIndex:\n",
    "        idx = InMemoryIndex(self.dim)\n",
    "        idx.add(encoded)\n",
    "        return idx\n",
    "\n",
    "\n",
    "class IdentityReranker:\n",
    "    def rerank(\n",
    "        self, query: Query, hits: Sequence[RetrievedDoc], top_k: Optional[int] = None\n",
    "    ) -> List[RetrievedDoc]:\n",
    "        out = list(hits)\n",
    "        if top_k is not None:\n",
    "            out = out[:top_k]\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---- Core text encoding (reusable) ------------------------------------------\n",
    "@node(output_name=\"cleaned_text\")\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "@node(output_name=\"embedding\")\n",
    "def encode_text(encoder: Encoder, cleaned_text: str, is_query: bool = False) -> Vector:\n",
    "    return encoder.encode(cleaned_text, is_query=is_query)\n",
    "\n",
    "\n",
    "# Reusable text encoding pipeline\n",
    "text_encode = Pipeline(nodes=[clean_text, encode_text])\n",
    "\n",
    "\n",
    "# ---- Passage encoding: extract -> encode -> pack ----------------------------\n",
    "@node(output_name=\"text\")\n",
    "def extract_passage_text(passage: Passage) -> str:\n",
    "    return passage.text\n",
    "\n",
    "\n",
    "@node(output_name=\"encoded_passage\")\n",
    "def pack_passage(passage: Passage, embedding: Vector) -> EncodedPassage:\n",
    "    return EncodedPassage(pid=passage.pid, text=passage.text, embedding=embedding)\n",
    "\n",
    "\n",
    "# Single passage encoding pipeline\n",
    "single_encode = Pipeline(nodes=[extract_passage_text, text_encode, pack_passage])\n",
    "\n",
    "# Visualize the DAG\n",
    "single_encode.visualize()\n",
    "\n",
    "# Test with single passage\n",
    "res = single_encode.run(\n",
    "    inputs={\n",
    "        \"passage\": Passage(pid=\"1\", text=\"Hello\"),\n",
    "        \"encoder\": NumpyRandomEncoder(dim=4, seed=42),\n",
    "        \"is_query\": False,\n",
    "    }\n",
    ")\n",
    "# res contains:\n",
    "# {\n",
    "#     \"text\": \"Hello\",\n",
    "#     \"cleaned_text\": \"hello\",\n",
    "#     \"embedding\": np.ndarray([...]),\n",
    "#     \"encoded_passage\": EncodedPassage(...)\n",
    "# }\n",
    "\n",
    "# Test with map over multiple passages\n",
    "results = single_encode.map(\n",
    "    inputs={\n",
    "        \"passage\": [Passage(pid=\"1\", text=\"Hello\"), Passage(pid=\"2\", text=\"World\")],\n",
    "        \"encoder\": NumpyRandomEncoder(dim=4, seed=42),\n",
    "        \"is_query\": False,\n",
    "    },\n",
    "    map_over=\"passage\",\n",
    ")\n",
    "# results contains:\n",
    "# {\n",
    "#     \"text\": [\"Hello\", \"World\"],\n",
    "#     \"cleaned_text\": [\"hello\", \"world\"],\n",
    "#     \"embedding\": [np.ndarray([...]), np.ndarray([...])],\n",
    "#     \"encoded_passage\": [EncodedPassage(...), EncodedPassage(...)]\n",
    "# }\n",
    "\n",
    "\n",
    "# ---- Index Building Pipeline ------------------------------------------------\n",
    "# Adapt single_encode to map over a corpus internally\n",
    "encode_corpus = single_encode.as_node(\n",
    "    input_mapping={\"corpus\": \"passage\"},\n",
    "    output_mapping={\"encoded_passage\": \"encoded_corpus\"},\n",
    "    map_over=\"corpus\",\n",
    ")\n",
    "\n",
    "\n",
    "@node(output_name=\"index\")\n",
    "def build_index(indexer: Indexer, encoded_corpus: List[EncodedPassage]) -> BaseIndex:\n",
    "    return indexer.index(encoded_corpus)\n",
    "\n",
    "\n",
    "# Pipeline: encode all passages, then build index\n",
    "encode_and_index = Pipeline(nodes=[encode_corpus, build_index])\n",
    "\n",
    "# Visualize\n",
    "encode_and_index.visualize()\n",
    "\n",
    "# Run with corpus\n",
    "corpus: List[Passage] = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"The Quick Brown Fox\"),\n",
    "]\n",
    "\n",
    "encoder = NumpyRandomEncoder(dim=4, seed=42)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\n",
    "        \"corpus\": corpus,\n",
    "        \"encoder\": encoder,\n",
    "        \"indexer\": indexer,\n",
    "        \"is_query\": False,\n",
    "    }\n",
    ")\n",
    "index: BaseIndex = outputs[\"index\"]\n",
    "\n",
    "\n",
    "# ---- Query encoding: extract -> encode --------------------------------------\n",
    "@node(output_name=\"text\")\n",
    "def extract_query_text(query: Query) -> str:\n",
    "    return query.text\n",
    "\n",
    "\n",
    "# Query encoding pipeline\n",
    "encode_query_pipeline = Pipeline(nodes=[extract_query_text, text_encode])\n",
    "\n",
    "# Use .as_node() to rename outputs\n",
    "encode_query_step = encode_query_pipeline.as_node(\n",
    "    output_mapping={\"embedding\": \"query_vec\"}\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Retrieval + Reranking --------------------------------------------------\n",
    "@node(output_name=\"retrieved\")\n",
    "def retrieve(\n",
    "    index: BaseIndex, query_vec: Vector, top_k: int = 10\n",
    ") -> List[RetrievedDoc]:\n",
    "    hits = index.search(query_vec, top_k=top_k)\n",
    "    return [\n",
    "        RetrievedDoc(\n",
    "            pid=h[\"pid\"],\n",
    "            text=index.get(h[\"pid\"]).text,\n",
    "            embedding=index.get(h[\"pid\"]).embedding,\n",
    "            score=h[\"score\"],\n",
    "        )\n",
    "        for h in hits\n",
    "    ]\n",
    "\n",
    "\n",
    "@node(output_name=\"reranked_hits\")\n",
    "def rerank_hits(\n",
    "    reranker: Reranker,\n",
    "    query: Query,\n",
    "    retrieved: List[RetrievedDoc],\n",
    "    final_top_k: Optional[int] = None,\n",
    ") -> List[RetrievedDoc]:\n",
    "    return reranker.rerank(query, retrieved, top_k=final_top_k)\n",
    "\n",
    "\n",
    "search_pipeline = Pipeline(nodes=[encode_query_step, retrieve, rerank_hits])\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline(nodes=[encode_and_index, search_pipeline])\n",
    "full_pipeline.visualize()\n",
    "\n",
    "\n",
    "# ---- Usage Examples ---------------------------------------------------------\n",
    "# Build index\n",
    "corpus = [\n",
    "    Passage(pid=\"p1\", text=\"Hello World\"),\n",
    "    Passage(pid=\"p2\", text=\"Quick Brown Fox\"),\n",
    "]\n",
    "encoder = NumpyRandomEncoder(dim=4)\n",
    "indexer = SimpleIndexer(dim=encoder.dim)\n",
    "\n",
    "outputs = encode_and_index.run(\n",
    "    inputs={\n",
    "        \"corpus\": corpus,\n",
    "        \"encoder\": encoder,\n",
    "        \"indexer\": indexer,\n",
    "        \"is_query\": False,\n",
    "    }\n",
    ")\n",
    "index = outputs[\"index\"]\n",
    "\n",
    "reranker = IdentityReranker()\n",
    "\n",
    "# Single query\n",
    "search_out = search_pipeline.run(\n",
    "    inputs={\n",
    "        \"query\": Query(text=\"hello world\"),\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "        \"is_query\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "for doc in search_out[\"reranked_hits\"]:\n",
    "    print(doc.pid, doc.score, doc.text)\n",
    "\n",
    "\n",
    "# Multiple queries\n",
    "queries = [Query(text=\"hello\"), Query(text=\"quick fox\"), Query(text=\"world\")]\n",
    "\n",
    "batch_out = search_pipeline.map(\n",
    "    inputs={\n",
    "        \"query\": queries,\n",
    "        \"encoder\": encoder,\n",
    "        \"index\": index,\n",
    "        \"reranker\": reranker,\n",
    "        \"top_k\": 5,\n",
    "        \"final_top_k\": 3,\n",
    "        \"is_query\": True,\n",
    "    },\n",
    "    map_over=\"query\",\n",
    ")\n",
    "\n",
    "for q, results in zip(queries, batch_out[\"reranked_hits\"]):\n",
    "    print(f\"\\nQuery: {q.text}\")\n",
    "    for r in results:\n",
    "        print(f\"  {r.pid} | {r.score:.3f} | {r.text}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

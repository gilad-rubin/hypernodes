{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439b0c60",
   "metadata": {},
   "source": [
    "# üìä Comprehensive Execution Strategy Comparison\n",
    "\n",
    "Comparing **Sequential**, **Async**, and **Threaded** execution for both:\n",
    "1. **Node-level execution** (running independent nodes in parallel)\n",
    "2. **Map-level execution** (running multiple items in parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96f06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modules reloaded\n"
     ]
    }
   ],
   "source": [
    "from hypernodes import Pipeline, node, HypernodesEngine\n",
    "from hypernodes.executors import AsyncExecutor\n",
    "\n",
    "print(\"‚úÖ Modules reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695202bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NODE-LEVEL EXECUTION (3 independent I/O tasks ‚Üí 1 combine)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Node-Level Execution Comparison\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "# Create pipeline with 3 independent I/O-bound tasks\n",
    "@node(output_name=\"task1\")\n",
    "def io_task1(x: int) -> int:\n",
    "    time.sleep(0.1)\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"task2\")\n",
    "def io_task2(x: int) -> int:\n",
    "    time.sleep(0.1)\n",
    "    return x * 3\n",
    "\n",
    "\n",
    "@node(output_name=\"task3\")\n",
    "def io_task3(x: int) -> int:\n",
    "    time.sleep(0.1)\n",
    "    return x * 4\n",
    "\n",
    "\n",
    "@node(output_name=\"final\")\n",
    "def combine_tasks(task1: int, task2: int, task3: int) -> dict:\n",
    "    return {\"task1\": task1, \"task2\": task2, \"task3\": task3}\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"NODE-LEVEL EXECUTION (3 independent I/O tasks ‚Üí 1 combine)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sequential\n",
    "pipeline_seq = Pipeline(\n",
    "    nodes=[io_task1, io_task2, io_task3, combine_tasks],\n",
    "    backend=HypernodesEngine(node_executor=\"sequential\"),\n",
    ")\n",
    "start = time.time()\n",
    "result_seq = pipeline_seq.run(inputs={\"x\": 10})\n",
    "time_seq = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496baa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Sequential:  0.314s (3 √ó 0.1s = 0.3s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîπ Sequential:  {time_seq:.3f}s (3 √ó 0.1s = 0.3s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131c317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async\n",
    "pipeline_seq = Pipeline(\n",
    "    nodes=[io_task1, io_task2, io_task3, combine_tasks],\n",
    "    backend=HypernodesEngine(node_executor=\"async\"),\n",
    ")\n",
    "start = time.time()\n",
    "result_seq = pipeline_seq.run(inputs={\"x\": 10})\n",
    "time_seq = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b6cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Async:  0.102s (3 √ó 0.1s = 0.3s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîπ Async:  {time_seq:.3f}s (3 √ó 0.1s = 0.3s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739d4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_seq = Pipeline(\n",
    "    nodes=[io_task1, io_task2, io_task3, combine_tasks],\n",
    "    backend=HypernodesEngine(node_executor=\"threaded\"),\n",
    ")\n",
    "start = time.time()\n",
    "result_seq = pipeline_seq.run(inputs={\"x\": 10})\n",
    "time_seq = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b5fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Threaded:  0.106s (3 √ó 0.1s = 0.3s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîπ Threaded:  {time_seq:.3f}s (3 √ó 0.1s = 0.3s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce703db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MAP-LEVEL EXECUTION (8 items, each taking 0.15s)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Map-Level Execution Comparison\n",
    "import time\n",
    "\n",
    "\n",
    "# Simple pipeline with one I/O-bound task\n",
    "@node(output_name=\"processed\")\n",
    "def process_item(x: int) -> int:\n",
    "    time.sleep(0.05)\n",
    "    return x**2\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MAP-LEVEL EXECUTION (8 items, each taking 0.15s)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "items_list = list(range(80))\n",
    "\n",
    "# Sequential Map\n",
    "pipeline_seq_map = Pipeline(\n",
    "    nodes=[process_item], backend=HypernodesEngine(map_executor=\"sequential\")\n",
    ")\n",
    "start = time.time()\n",
    "results_seq_map = pipeline_seq_map.map(inputs={\"x\": items_list}, map_over=\"x\")\n",
    "time_seq_map = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e5cc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Sequential Map:  4.326s (8 √ó 0.15s = 1.2s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîπ Sequential Map:  {time_seq_map:.3f}s (8 √ó 0.15s = 1.2s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e7f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_async_map = Pipeline(\n",
    "    nodes=[process_item],\n",
    "    backend=HypernodesEngine(map_executor=AsyncExecutor(max_workers=100)),\n",
    ")\n",
    "start = time.time()\n",
    "results_async_map = pipeline_async_map.map(inputs={\"x\": items_list}, map_over=\"x\")\n",
    "time_async_map = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd933033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Async Map:       0.331s (concurrent: ~0.15s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîπ Async Map:       {time_async_map:.3f}s (concurrent: ~0.15s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d49165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threaded Map\n",
    "pipeline_thread_map = Pipeline(\n",
    "    nodes=[process_item],\n",
    "    backend=HypernodesEngine(map_executor=ThreadPoolExecutor(max_workers=100)),\n",
    ")\n",
    "start = time.time()\n",
    "results_thread_map = pipeline_thread_map.map(inputs={\"x\": items_list}, map_over=\"x\")\n",
    "time_thread_map = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80fdea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Threaded Map:    0.069s (4 workers: ~0.3s expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîπ Threaded Map:    {time_thread_map:.3f}s (4 workers: ~0.3s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57890af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Parallel Map:    1.324s (8 workers: ~0.3s expected)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Parallel Map (loky)\n",
    "pipeline_par_map = Pipeline(\n",
    "    nodes=[process_item],\n",
    "    backend=HypernodesEngine(map_executor=\"parallel\", max_workers=os.cpu_count()),\n",
    ")\n",
    "start = time.time()\n",
    "results_par_map = pipeline_par_map.map(inputs={\"x\": items_list}, map_over=\"x\")\n",
    "time_par_map = time.time() - start\n",
    "print(f\"üîπ Parallel Map:    {time_par_map:.3f}s (8 workers: ~0.3s expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db957865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Speedup vs Sequential:\n",
      "   Async:    13.06x faster\n",
      "   Threaded: 62.30x faster\n",
      "   Parallel: 3.27x faster\n",
      "\n",
      "üí° Best for:\n",
      "   ‚Ä¢ Sequential: Debugging, simple workflows\n",
      "   ‚Ä¢ Async:      I/O-bound async operations (API calls, DB queries)\n",
      "   ‚Ä¢ Threaded:   I/O-bound blocking operations (file I/O, requests)\n",
      "   ‚Ä¢ Parallel:   CPU-bound computations (heavy processing)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìä Speedup vs Sequential:\")\n",
    "print(f\"   Async:    {time_seq_map / time_async_map:.2f}x faster\")\n",
    "print(f\"   Threaded: {time_seq_map / time_thread_map:.2f}x faster\")\n",
    "print(f\"   Parallel: {time_seq_map / time_par_map:.2f}x faster\")\n",
    "\n",
    "print(f\"\\nüí° Best for:\")\n",
    "print(f\"   ‚Ä¢ Sequential: Debugging, simple workflows\")\n",
    "print(f\"   ‚Ä¢ Async:      I/O-bound async operations (API calls, DB queries)\")\n",
    "print(f\"   ‚Ä¢ Threaded:   I/O-bound blocking operations (file I/O, requests)\")\n",
    "print(f\"   ‚Ä¢ Parallel:   CPU-bound computations (heavy processing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cda054",
   "metadata": {},
   "source": [
    "# üîç Performance Analysis\n",
    "\n",
    "## Why Threaded is Fastest Here\n",
    "\n",
    "Your results make sense! Here's why:\n",
    "\n",
    "**Threaded (42x faster)** wins because:\n",
    "- ‚úÖ Direct ThreadPoolExecutor with 100 workers\n",
    "- ‚úÖ Minimal overhead - just thread creation\n",
    "- ‚úÖ Perfect for blocking I/O (time.sleep)\n",
    "- ‚úÖ All 80 items run concurrently (you have 100 workers!)\n",
    "\n",
    "**Async (13x faster)** is slower than Threaded because:\n",
    "- ‚ö†Ô∏è `run_in_executor(None)` uses asyncio's default thread pool (limited size)\n",
    "- ‚ö†Ô∏è Semaphore limits concurrency to max_workers\n",
    "- ‚ö†Ô∏è Extra overhead from event loop management\n",
    "- ‚ÑπÔ∏è For sync functions, AsyncExecutor wraps them in threads anyway!\n",
    "\n",
    "**Parallel (3.9x faster)** is slowest because:\n",
    "- ‚ùå Process spawning overhead (~1s for 80 processes)\n",
    "- ‚ùå IPC (serialization/deserialization) overhead\n",
    "- ‚ùå For short tasks (0.05s), overhead > task time\n",
    "- ‚úÖ Only worth it for CPU-bound tasks > 0.5s each\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "For **blocking I/O with sync functions**: `ThreadPoolExecutor` is the clear winner!\n",
    "\n",
    "AsyncExecutor is best when you have **native async functions** (async def with await)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee6b8f",
   "metadata": {},
   "source": [
    "# üí° Optimization Recommendations\n",
    "\n",
    "## For Better Async Performance\n",
    "\n",
    "The AsyncExecutor can be optimized by:\n",
    "\n",
    "1. **Using native async functions** instead of sync+sleep:\n",
    "```python\n",
    "@node\n",
    "async def async_process(x: int) -> int:\n",
    "    await asyncio.sleep(0.05)  # Non-blocking!\n",
    "    return x**2\n",
    "```\n",
    "\n",
    "2. **Increasing default thread pool size** for sync functions:\n",
    "```python\n",
    "# asyncio's default thread pool is limited\n",
    "# AsyncExecutor wraps sync functions with run_in_executor(None, ...)\n",
    "# which uses the default pool\n",
    "```\n",
    "\n",
    "## For Better Parallel Performance\n",
    "\n",
    "ProcessPoolExecutor shines when:\n",
    "- Tasks are **CPU-bound** (actual computation)\n",
    "- Task duration **> 0.5s** (overhead becomes negligible)\n",
    "- Example: numpy operations, ML inference, image processing\n",
    "\n",
    "```python\n",
    "@node\n",
    "def cpu_intensive(x: int) -> int:\n",
    "    # Heavy computation (not just sleep!)\n",
    "    return sum(i**2 for i in range(x * 1000000))\n",
    "```\n",
    "\n",
    "## Current Best Practices\n",
    "\n",
    "| Scenario | Best Executor | Why |\n",
    "|----------|---------------|-----|\n",
    "| **Sync blocking I/O** | ThreadPoolExecutor | Minimal overhead, direct threading |\n",
    "| **Async I/O (native async)** | AsyncExecutor | Efficient event loop, no blocking |\n",
    "| **CPU-bound (short)** | ThreadPoolExecutor | Less overhead than processes |\n",
    "| **CPU-bound (long >0.5s)** | ProcessPoolExecutor | Bypasses GIL, true parallelism |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857f26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß™ ASYNC OPTIMIZATION TEST: Native async vs Sync-wrapped\n",
      "======================================================================\n",
      "\n",
      "üìä Results (40 items, 0.05s each):\n",
      "   1Ô∏è‚É£  Native async + AsyncExecutor:        0.163s\n",
      "   2Ô∏è‚É£  Sync wrapped + AsyncExecutor:        0.164s\n",
      "   3Ô∏è‚É£  Sync + ThreadPoolExecutor:           0.059s\n",
      "   4Ô∏è‚É£  Direct ThreadPoolExecutor + async:   0.059s\n",
      "\n",
      "üí° Key Insight:\n",
      "   ‚ö†Ô∏è  Similar performance - overhead dominates\n",
      "   ‚úÖ Direct ThreadPoolExecutor is 2.8x faster!\n",
      "   ‚úÖ For sync blocking I/O, use ThreadPoolExecutor directly\n"
     ]
    }
   ],
   "source": [
    "# Test: Native Async vs Sync-wrapped\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ ASYNC OPTIMIZATION TEST: Native async vs Sync-wrapped\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# Native async function (non-blocking)\n",
    "@node(output_name=\"async_result\")\n",
    "async def native_async_fn(x: int) -> int:\n",
    "    await asyncio.sleep(0.05)  # Non-blocking async sleep\n",
    "    return x**2\n",
    "\n",
    "\n",
    "# Sync function (will be auto-wrapped by AsyncExecutor)\n",
    "@node(output_name=\"sync_result\")\n",
    "def sync_fn(x: int) -> int:\n",
    "    time.sleep(0.05)  # Blocking sleep\n",
    "    return x**2\n",
    "\n",
    "\n",
    "items = list(range(40))\n",
    "\n",
    "# Test 1: Native async with AsyncExecutor\n",
    "pipeline_native_async = Pipeline(\n",
    "    nodes=[native_async_fn],\n",
    "    backend=HypernodesEngine(map_executor=AsyncExecutor(max_workers=100)),\n",
    ")\n",
    "start = time.time()\n",
    "results_native = pipeline_native_async.map(inputs={\"x\": items}, map_over=\"x\")\n",
    "time_native = time.time() - start\n",
    "\n",
    "# Test 2: Sync wrapped by AsyncExecutor\n",
    "pipeline_wrapped_sync = Pipeline(\n",
    "    nodes=[sync_fn],\n",
    "    backend=HypernodesEngine(map_executor=AsyncExecutor(max_workers=100)),\n",
    ")\n",
    "start = time.time()\n",
    "results_wrapped = pipeline_wrapped_sync.map(inputs={\"x\": items}, map_over=\"x\")\n",
    "time_wrapped = time.time() - start\n",
    "\n",
    "# Test 3: Direct ThreadPoolExecutor\n",
    "pipeline_direct_thread = Pipeline(\n",
    "    nodes=[sync_fn],\n",
    "    backend=HypernodesEngine(\n",
    "        map_executor=ThreadPoolExecutor(max_workers=100),\n",
    "    ),\n",
    ")\n",
    "start = time.time()\n",
    "results_thread = pipeline_direct_thread.map(inputs={\"x\": items}, map_over=\"x\")\n",
    "time_thread = time.time() - start\n",
    "\n",
    "# Test 4: Direct ThreadPoolExecutor + async node_executor\n",
    "pipeline_direct_thread = Pipeline(\n",
    "    nodes=[sync_fn],\n",
    "    backend=HypernodesEngine(\n",
    "        map_executor=ThreadPoolExecutor(max_workers=100), node_executor=\"async\"\n",
    "    ),\n",
    ")\n",
    "start = time.time()\n",
    "results_thread_async = pipeline_direct_thread.map(inputs={\"x\": items}, map_over=\"x\")\n",
    "time_thread_async = time.time() - start\n",
    "\n",
    "print(f\"\\nüìä Results (40 items, 0.05s each):\")\n",
    "print(f\"   1Ô∏è‚É£  Native async + AsyncExecutor:        {time_native:.3f}s\")\n",
    "print(f\"   2Ô∏è‚É£  Sync wrapped + AsyncExecutor:        {time_wrapped:.3f}s\")\n",
    "print(f\"   3Ô∏è‚É£  Sync + ThreadPoolExecutor:           {time_thread:.3f}s\")\n",
    "print(f\"   4Ô∏è‚É£  Direct ThreadPoolExecutor + async:   {time_thread_async:.3f}s\")\n",
    "\n",
    "print(f\"\\nüí° Key Insight:\")\n",
    "if time_native < time_wrapped * 0.8:\n",
    "    print(\n",
    "        f\"   ‚úÖ Native async is {time_wrapped / time_native:.1f}x faster than wrapped sync!\"\n",
    "    )\n",
    "    print(f\"   ‚úÖ Use async def + await for best AsyncExecutor performance\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Similar performance - overhead dominates\")\n",
    "\n",
    "if time_thread < time_wrapped * 0.8:\n",
    "    print(\n",
    "        f\"   ‚úÖ Direct ThreadPoolExecutor is {time_wrapped / time_thread:.1f}x faster!\"\n",
    "    )\n",
    "    print(f\"   ‚úÖ For sync blocking I/O, use ThreadPoolExecutor directly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e219d796",
   "metadata": {},
   "source": [
    "# ‚úÖ Final Recommendations\n",
    "\n",
    "## TL;DR: Choose the Right Executor\n",
    "\n",
    "Based on the benchmarks above:\n",
    "\n",
    "### For Blocking I/O (time.sleep, requests, file I/O)\n",
    "**Winner: ThreadPoolExecutor** üèÜ\n",
    "- 3x faster than AsyncExecutor for sync functions\n",
    "- Minimal overhead\n",
    "- Simple and direct\n",
    "\n",
    "```python\n",
    "Pipeline(nodes=[...], backend=HypernodesEngine(\n",
    "    map_executor=ThreadPoolExecutor(max_workers=100)\n",
    "))\n",
    "```\n",
    "\n",
    "### For Async I/O (aiohttp, asyncpg, aiofiles)\n",
    "**Winner: AsyncExecutor with native async** üèÜ\n",
    "- Use `async def` + `await` for truly async operations\n",
    "- Don't mix sync blocking I/O here\n",
    "\n",
    "```python\n",
    "@node\n",
    "async def fetch_data(url: str) -> dict:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        response = await session.get(url)\n",
    "        return await response.json()\n",
    "```\n",
    "\n",
    "### For CPU-Bound Work (> 0.5s per item)\n",
    "**Winner: ProcessPoolExecutor (\"parallel\")** üèÜ\n",
    "- True parallelism (bypasses GIL)\n",
    "- Overhead is negligible for long tasks\n",
    "\n",
    "```python\n",
    "Pipeline(nodes=[...], backend=HypernodesEngine(\n",
    "    map_executor=\"parallel\", max_workers=cpu_count()\n",
    "))\n",
    "```\n",
    "\n",
    "## Why AsyncExecutor is Slower for Sync Functions\n",
    "\n",
    "When you use `AsyncExecutor` with sync functions:\n",
    "1. Function gets wrapped with `loop.run_in_executor(None, func)`\n",
    "2. This submits to asyncio's **default ThreadPoolExecutor**\n",
    "3. Default pool has limited size + event loop overhead\n",
    "4. Result: **Slower than direct ThreadPoolExecutor!**\n",
    "\n",
    "**Bottom line**: For sync blocking I/O, skip the middleman and use `ThreadPoolExecutor` directly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ec537",
   "metadata": {},
   "source": [
    "# üß™ Real-World Scenarios: When Each Executor Shines\n",
    "\n",
    "## Scenario 1: CPU-Bound (Parallel Should Win)\n",
    "Heavy computation where process-based parallelism bypasses the GIL\n",
    "\n",
    "## Scenario 2: Async I/O (Async Should Win)\n",
    "Native async operations with non-blocking I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b743aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß™ SCENARIO 1: CPU-BOUND (heavy computation)\n",
      "======================================================================\n",
      "\n",
      "üîπ Sequential: 0.936s (baseline)\n"
     ]
    }
   ],
   "source": [
    "# Scenario 1: CPU-Bound Computation (Parallel should win)\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ SCENARIO 1: CPU-BOUND (heavy computation)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "@node(output_name=\"hash_result\")\n",
    "def compute_heavy_hash(text: str) -> str:\n",
    "    \"\"\"CPU-intensive hashing operation\"\"\"\n",
    "    result = text\n",
    "    # Do 100,000 iterations of hashing (CPU-bound)\n",
    "    for _ in range(100_000):\n",
    "        result = hashlib.sha256(result.encode()).hexdigest()\n",
    "    return result[:16]\n",
    "\n",
    "\n",
    "# Test with 20 items (enough to see parallelism benefit, not too slow)\n",
    "cpu_items = [f\"item_{i}\" for i in range(20)]\n",
    "\n",
    "# Test 1: Sequential (baseline)\n",
    "pipeline_cpu_seq = Pipeline(\n",
    "    nodes=[compute_heavy_hash], backend=HypernodesEngine(map_executor=\"sequential\")\n",
    ")\n",
    "start = time.time()\n",
    "results_cpu_seq = pipeline_cpu_seq.map(inputs={\"text\": cpu_items}, map_over=\"text\")\n",
    "time_cpu_seq = time.time() - start\n",
    "\n",
    "print(f\"\\nüîπ Sequential: {time_cpu_seq:.3f}s (baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c12343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Threaded:   0.963s (0.97x speedup - GIL limits!)\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Threaded (should be similar to sequential due to GIL)\n",
    "pipeline_cpu_thread = Pipeline(\n",
    "    nodes=[compute_heavy_hash],\n",
    "    backend=HypernodesEngine(\n",
    "        map_executor=ThreadPoolExecutor(max_workers=os.cpu_count())\n",
    "    ),\n",
    ")\n",
    "start = time.time()\n",
    "results_cpu_thread = pipeline_cpu_thread.map(\n",
    "    inputs={\"text\": cpu_items}, map_over=\"text\"\n",
    ")\n",
    "time_cpu_thread = time.time() - start\n",
    "\n",
    "print(\n",
    "    f\"üîπ Threaded:   {time_cpu_thread:.3f}s ({time_cpu_seq / time_cpu_thread:.2f}x speedup - GIL limits!)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19342902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Parallel:   0.201s (4.66x speedup - TRUE parallelism!)\n",
      "\n",
      "üìä CPU-Bound Results:\n",
      "   Parallel speedup: 4.66x (expected: ~10x)\n",
      "   Threaded speedup: 0.97x (GIL prevents parallelism)\n",
      "\n",
      "‚úÖ Parallel is 4.79x faster than Threaded for CPU-bound work!\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Parallel (should win - bypasses GIL!)\n",
    "pipeline_cpu_par = Pipeline(\n",
    "    nodes=[compute_heavy_hash],\n",
    "    backend=HypernodesEngine(map_executor=\"parallel\", max_workers=os.cpu_count()),\n",
    ")\n",
    "start = time.time()\n",
    "results_cpu_par = pipeline_cpu_par.map(inputs={\"text\": cpu_items}, map_over=\"text\")\n",
    "time_cpu_par = time.time() - start\n",
    "\n",
    "print(\n",
    "    f\"üîπ Parallel:   {time_cpu_par:.3f}s ({time_cpu_seq / time_cpu_par:.2f}x speedup - TRUE parallelism!)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä CPU-Bound Results:\")\n",
    "print(\n",
    "    f\"   Parallel speedup: {time_cpu_seq / time_cpu_par:.2f}x (expected: ~{os.cpu_count()}x)\"\n",
    ")\n",
    "print(\n",
    "    f\"   Threaded speedup: {time_cpu_seq / time_cpu_thread:.2f}x (GIL prevents parallelism)\"\n",
    ")\n",
    "print(\n",
    "    f\"\\n‚úÖ Parallel is {time_cpu_thread / time_cpu_par:.2f}x faster than Threaded for CPU-bound work!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe9af51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß™ SCENARIO 2: ASYNC I/O (native async operations)\n",
      "======================================================================\n",
      "\n",
      "üîπ Sequential (sync): 5.196s (baseline)\n"
     ]
    }
   ],
   "source": [
    "# Scenario 2: Native Async I/O (Async should win)\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üß™ SCENARIO 2: ASYNC I/O (native async operations)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "@node(output_name=\"async_fetch\")\n",
    "async def async_io_operation(delay: float) -> dict:\n",
    "    \"\"\"Simulates async I/O like API calls\"\"\"\n",
    "    start = time.time()\n",
    "    await asyncio.sleep(delay)  # Non-blocking async sleep\n",
    "    return {\"delay\": delay, \"duration\": time.time() - start}\n",
    "\n",
    "\n",
    "# Test with 50 items (0.1s each = 5s sequential)\n",
    "async_delays = [0.1] * 50\n",
    "\n",
    "\n",
    "# Test 1: Sequential (baseline)\n",
    "@node(output_name=\"sync_fetch\")\n",
    "def sync_io_operation(delay: float) -> dict:\n",
    "    \"\"\"Simulates sync I/O\"\"\"\n",
    "    start = time.time()\n",
    "    time.sleep(delay)  # Blocking sleep\n",
    "    return {\"delay\": delay, \"duration\": time.time() - start}\n",
    "\n",
    "\n",
    "pipeline_io_seq = Pipeline(\n",
    "    nodes=[sync_io_operation], backend=HypernodesEngine(map_executor=\"sequential\")\n",
    ")\n",
    "start = time.time()\n",
    "results_io_seq = pipeline_io_seq.map(inputs={\"delay\": async_delays}, map_over=\"delay\")\n",
    "time_io_seq = time.time() - start\n",
    "\n",
    "print(f\"\\nüîπ Sequential (sync): {time_io_seq:.3f}s (baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6167c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Threaded (sync):   0.120s (43.15x speedup)\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Threaded (sync blocking I/O)\n",
    "pipeline_io_thread = Pipeline(\n",
    "    nodes=[sync_io_operation],\n",
    "    backend=HypernodesEngine(map_executor=ThreadPoolExecutor(max_workers=50)),\n",
    ")\n",
    "start = time.time()\n",
    "results_io_thread = pipeline_io_thread.map(\n",
    "    inputs={\"delay\": async_delays}, map_over=\"delay\"\n",
    ")\n",
    "time_io_thread = time.time() - start\n",
    "\n",
    "print(\n",
    "    f\"üîπ Threaded (sync):   {time_io_thread:.3f}s ({time_io_seq / time_io_thread:.2f}x speedup)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08f8cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Async (native):    0.418s (12.44x speedup - efficient concurrency!)\n",
      "\n",
      "üìä Async I/O Results:\n",
      "   Async speedup:    12.44x (minimal overhead)\n",
      "   Threaded speedup: 43.15x (thread overhead)\n",
      "\n",
      "‚úÖ Async is 0.29x faster than Threaded for native async I/O!\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Async (native async - should win!)\n",
    "pipeline_io_async = Pipeline(\n",
    "    nodes=[async_io_operation],\n",
    "    backend=HypernodesEngine(map_executor=AsyncExecutor(max_workers=50)),\n",
    ")\n",
    "start = time.time()\n",
    "results_io_async = pipeline_io_async.map(\n",
    "    inputs={\"delay\": async_delays}, map_over=\"delay\"\n",
    ")\n",
    "time_io_async = time.time() - start\n",
    "\n",
    "print(\n",
    "    f\"üîπ Async (native):    {time_io_async:.3f}s ({time_io_seq / time_io_async:.2f}x speedup - efficient concurrency!)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Async I/O Results:\")\n",
    "print(f\"   Async speedup:    {time_io_seq / time_io_async:.2f}x (minimal overhead)\")\n",
    "print(f\"   Threaded speedup: {time_io_seq / time_io_thread:.2f}x (thread overhead)\")\n",
    "print(\n",
    "    f\"\\n‚úÖ Async is {time_io_thread / time_io_async:.2f}x faster than Threaded for native async I/O!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50284d15",
   "metadata": {},
   "source": [
    "# üéØ Final Decision Matrix\n",
    "\n",
    "| Workload Type | Best Executor | Expected Speedup | Why |\n",
    "|---------------|---------------|------------------|-----|\n",
    "| **CPU-Bound (>0.5s/item)** | `\"parallel\"` (ProcessPoolExecutor) | ~N cores | Bypasses GIL, true parallelism |\n",
    "| **Sync Blocking I/O** | `ThreadPoolExecutor` | ~N workers | Minimal overhead, simple threading |\n",
    "| **Native Async I/O** | `AsyncExecutor` (with `async def`) | ~N workers | Efficient event loop, no blocking |\n",
    "| **Mixed CPU + I/O** | `ThreadPoolExecutor` | 2-4x | Good balance |\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Parallel wins for CPU-bound**: When GIL is the bottleneck\n",
    "2. **Async wins for native async I/O**: When you have `async def` + `await`\n",
    "3. **Threaded is the practical choice**: For most sync blocking I/O (requests, file I/O)\n",
    "\n",
    "**Pro tip**: If your function is `def` (not `async def`), use `ThreadPoolExecutor` directly instead of `AsyncExecutor`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernodes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

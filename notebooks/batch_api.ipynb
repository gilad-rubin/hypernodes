{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8f671cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'ipywidgets.widgets.widget_string.HTML'> 10330\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6dbf26affe6047618d8791c3d90635e0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "HTML(value='<iframe src=\"data:text/html;base64,CjwhRE9DVFlQRSBodG1sPgo8aHRtbD4KPGhlYWQ+CiAgICA8bWV0YSBjaGFyc2Vâ€¦"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from hypernodes import Pipeline, node\n",
                "\n",
                "\n",
                "@node(output_name=\"y\")\n",
                "def add1(x: int):\n",
                "    return x + 1\n",
                "\n",
                "\n",
                "w = Pipeline(nodes=[add1]).visualize(engine=\"ipywidget\")\n",
                "print(type(w), len(w.value))\n",
                "w  # should render the iframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "cf8c92da",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "======================================================================\n",
                        "Semantic Search Pipeline with DualNode\n",
                        "======================================================================\n",
                        "\n",
                        "This demonstrates:\n",
                        "  - Batch-optimized encoding using DualNode\n",
                        "  - Semantic search with nearest neighbor retrieval\n",
                        "  - Comparison of SeqEngine vs DaftEngine\n",
                        "\n",
                        "======================================================================\n",
                        "Testing with SeqEngine\n",
                        "======================================================================\n",
                        "[INIT] Loading encoder: mock-encoder-v1 (dim=384)\n",
                        "\n",
                        "[STEP 1] Encoding 10 passages...\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "Failed to convert input 'encoder' to PyArrow Array: Could not convert <__main__.MockEncoder object at 0x10d9eb4a0> with type MockEncoder: did not recognize Python value type when inferring an Arrow data type\nDualNode batch functions require inputs that can be converted to pa.Array.\nFor complex types (dataclasses, custom objects), use regular nodes with .map() instead.\nBatch optimization is intended for vectorized operations on primitive types.",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mArrowInvalid\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/sequential_engine.py:265\u001b[39m, in \u001b[36mSeqEngine._execute_dual_node_batch\u001b[39m\u001b[34m(self, node, items, stateful_cache, pipeline, output_name, orchestrator)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     arrow_inputs[k] = \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:375\u001b[39m, in \u001b[36mpyarrow.lib.array\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:46\u001b[39m, in \u001b[36mpyarrow.lib._sequence_to_array\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[39m, in \u001b[36mpyarrow.lib.pyarrow_internal_check_status\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
                        "\u001b[31mArrowInvalid\u001b[39m: Could not convert <__main__.MockEncoder object at 0x10d9eb4a0> with type MockEncoder: did not recognize Python value type when inferring an Arrow data type",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 412\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  - Comparison of SeqEngine vs DaftEngine\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Test with SeqEngine\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m seq_results = \u001b[43mtest_sequential_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Test with DaftEngine\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# daft_results = test_daft_engine()\u001b[39;00m\n\u001b[32m    416\u001b[39m \n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Verify consistency\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# verify_consistency(seq_results, daft_results)\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mtest_sequential_engine\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    220\u001b[39m encoding_pipeline = create_encoding_pipeline()\n\u001b[32m    222\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m passage_results = \u001b[43mencoding_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_over\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m encoding_time = time.time() - start_time\n\u001b[32m    228\u001b[39m passage_embeddings = [r[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m passage_results]\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/pipeline.py:177\u001b[39m, in \u001b[36mPipeline.map\u001b[39m\u001b[34m(self, inputs, map_over, map_mode, output_name, engine, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m     map_over = [map_over]\n\u001b[32m    176\u001b[39m exec_engine = engine \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexec_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_over\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/sequential_engine.py:78\u001b[39m, in \u001b[36mSeqEngine.map\u001b[39m\u001b[34m(self, pipeline, inputs, map_over, map_mode, output_name, _ctx, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Execute\u001b[39;00m\n\u001b[32m     76\u001b[39m orchestrator.notify_map_start(\u001b[38;5;28mlen\u001b[39m(items))\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_map_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstateful_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morchestrator\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m orchestrator.notify_map_end()\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/sequential_engine.py:193\u001b[39m, in \u001b[36mSeqEngine._execute_map_loop\u001b[39m\u001b[34m(self, items, stateful_cache, pipeline, output_name, orchestrator)\u001b[39m\n\u001b[32m    187\u001b[39m execution_nodes = \u001b[38;5;28mself\u001b[39m._determine_execution_nodes(pipeline, output_name)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mlen\u001b[39m(execution_nodes) == \u001b[32m1\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(execution_nodes[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mis_dual_node\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    191\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m execution_nodes[\u001b[32m0\u001b[39m].is_dual_node\n\u001b[32m    192\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_dual_node_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_nodes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstateful_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43morchestrator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m results = []\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, item_inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(items):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/sequential_engine.py:267\u001b[39m, in \u001b[36mSeqEngine._execute_dual_node_batch\u001b[39m\u001b[34m(self, node, items, stateful_cache, pipeline, output_name, orchestrator)\u001b[39m\n\u001b[32m    265\u001b[39m             arrow_inputs[k] = pa.array(v)\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    268\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to convert input \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to PyArrow Array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDualNode batch functions require inputs that can be converted to pa.Array.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFor complex types (dataclasses, custom objects), use regular nodes with .map() instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    271\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch optimization is intended for vectorized operations on primitive types.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    272\u001b[39m             )\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# 3. Execute Batch Function\u001b[39;00m\n\u001b[32m    275\u001b[39m ctx = orchestrator.ctx\n",
                        "\u001b[31mTypeError\u001b[39m: Failed to convert input 'encoder' to PyArrow Array: Could not convert <__main__.MockEncoder object at 0x10d9eb4a0> with type MockEncoder: did not recognize Python value type when inferring an Arrow data type\nDualNode batch functions require inputs that can be converted to pa.Array.\nFor complex types (dataclasses, custom objects), use regular nodes with .map() instead.\nBatch optimization is intended for vectorized operations on primitive types."
                    ]
                }
            ],
            "source": [
                "\"\"\"Semantic search pipeline using DualNode for batch-optimized encoding.\n",
                "\n",
                "This script demonstrates:\n",
                "- Encoding k passages (corpus)\n",
                "- Encoding m queries\n",
                "- Finding nearest neighbors for each query\n",
                "- Using DualNode for batch optimization\n",
                "- Testing with both SeqEngine and DaftEngine\n",
                "\"\"\"\n",
                "\n",
                "import time\n",
                "from typing import List\n",
                "\n",
                "import numpy as np\n",
                "\n",
                "from hypernodes import DualNode, Pipeline\n",
                "\n",
                "try:\n",
                "    from daft import Series\n",
                "\n",
                "    from hypernodes.engines import DaftEngine\n",
                "\n",
                "    DAFT_AVAILABLE = True\n",
                "except ImportError:\n",
                "    DAFT_AVAILABLE = False\n",
                "    Series = List\n",
                "    print(\"âš ï¸  Daft not available - will only test SeqEngine\")\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Mock Encoder (simulates sentence transformers)\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "class MockEncoder:\n",
                "    \"\"\"Simulates a sentence encoder with batch capability.\"\"\"\n",
                "\n",
                "    def __init__(self, model_name: str, embedding_dim: int = 384):\n",
                "        self.model_name = model_name\n",
                "        self.embedding_dim = embedding_dim\n",
                "        print(f\"[INIT] Loading encoder: {model_name} (dim={embedding_dim})\")\n",
                "\n",
                "    def encode(self, text: str) -> List[float]:\n",
                "        \"\"\"Encode single text (deterministic based on hash).\"\"\"\n",
                "        # Deterministic encoding based on text hash\n",
                "        np.random.seed(hash(text) % (2**32))\n",
                "        return np.random.randn(self.embedding_dim).tolist()\n",
                "\n",
                "    def encode_batch(self, texts: Series) -> Series:\n",
                "        \"\"\"Encode batch of texts efficiently.\"\"\"\n",
                "        text_list = texts.to_pylist() if hasattr(texts, \"to_pylist\") else texts\n",
                "        embeddings = [self.encode(text) for text in text_list]\n",
                "\n",
                "        if hasattr(Series, \"from_pylist\"):\n",
                "            return Series.from_pylist(embeddings)\n",
                "        return embeddings\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# DualNode Functions: Encoding\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "def encode_text(text: str, encoder: MockEncoder) -> List[float]:\n",
                "    \"\"\"Encode single text.\"\"\"\n",
                "    return encoder.encode(text)\n",
                "\n",
                "\n",
                "def encode_text_batch(texts: Series, encoder: MockEncoder) -> Series:\n",
                "    \"\"\"Encode batch of texts (optimized).\"\"\"\n",
                "    return encoder.encode_batch(texts)\n",
                "\n",
                "\n",
                "# Create DualNode for encoding\n",
                "encode_node = DualNode(\n",
                "    output_name=\"embedding\",\n",
                "    singular=encode_text,\n",
                "    batch=encode_text_batch,\n",
                ")\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Regular function: Find nearest neighbors\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
                "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
                "    vec1_arr = np.array(vec1)\n",
                "    vec2_arr = np.array(vec2)\n",
                "\n",
                "    dot_product = np.dot(vec1_arr, vec2_arr)\n",
                "    norm1 = np.linalg.norm(vec1_arr)\n",
                "    norm2 = np.linalg.norm(vec2_arr)\n",
                "\n",
                "    if norm1 == 0 or norm2 == 0:\n",
                "        return 0.0\n",
                "\n",
                "    return float(dot_product / (norm1 * norm2))\n",
                "\n",
                "\n",
                "def find_nearest_passages(\n",
                "    embedding: List[float],\n",
                "    passage_embeddings: List[List[float]],\n",
                "    passages: List[str],\n",
                "    top_k: int = 3,\n",
                ") -> List[dict]:\n",
                "    \"\"\"Find top-k nearest passages for a single query.\"\"\"\n",
                "    # Compute similarities\n",
                "    similarities = [\n",
                "        cosine_similarity(embedding, passage_emb) for passage_emb in passage_embeddings\n",
                "    ]\n",
                "\n",
                "    # Get top-k indices\n",
                "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
                "\n",
                "    # Return results\n",
                "    results = []\n",
                "    for idx in top_indices:\n",
                "        results.append(\n",
                "            {\n",
                "                \"passage\": passages[idx],\n",
                "                \"score\": float(similarities[idx]),\n",
                "                \"rank\": len(results) + 1,\n",
                "            }\n",
                "        )\n",
                "\n",
                "    return results\n",
                "\n",
                "\n",
                "def find_nearest_passages_batch(\n",
                "    embeddings: Series,\n",
                "    passage_embeddings: List[List[float]],\n",
                "    passages: List[str],\n",
                "    top_k: int = 3,\n",
                ") -> Series:\n",
                "    \"\"\"Find top-k nearest passages for batch of queries.\"\"\"\n",
                "    emb_list = (\n",
                "        embeddings.to_pylist() if hasattr(embeddings, \"to_pylist\") else embeddings\n",
                "    )\n",
                "\n",
                "    results = [\n",
                "        find_nearest_passages(emb, passage_embeddings, passages, top_k)\n",
                "        for emb in emb_list\n",
                "    ]\n",
                "\n",
                "    if hasattr(Series, \"from_pylist\"):\n",
                "        return Series.from_pylist(results)\n",
                "    return results\n",
                "\n",
                "\n",
                "# Create DualNode for nearest neighbor search\n",
                "search_node = DualNode(\n",
                "    output_name=\"search_results\",\n",
                "    singular=find_nearest_passages,\n",
                "    batch=find_nearest_passages_batch,\n",
                ")\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Test Data\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "def create_test_data(num_passages: int = 10, num_queries: int = 3):\n",
                "    \"\"\"Create test passages and queries.\"\"\"\n",
                "    passages = [\n",
                "        \"Machine learning is a subset of artificial intelligence.\",\n",
                "        \"Deep learning uses neural networks with multiple layers.\",\n",
                "        \"Natural language processing helps computers understand text.\",\n",
                "        \"Computer vision enables machines to interpret visual data.\",\n",
                "        \"Reinforcement learning trains agents through rewards.\",\n",
                "        \"Supervised learning uses labeled training data.\",\n",
                "        \"Unsupervised learning finds patterns in unlabeled data.\",\n",
                "        \"Transfer learning reuses pre-trained models.\",\n",
                "        \"Generative AI creates new content from learned patterns.\",\n",
                "        \"Large language models process and generate human-like text.\",\n",
                "    ][:num_passages]\n",
                "\n",
                "    queries = [\n",
                "        \"What is deep learning?\",\n",
                "        \"How do computers understand language?\",\n",
                "        \"Tell me about AI training methods.\",\n",
                "    ][:num_queries]\n",
                "\n",
                "    return passages, queries\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Pipeline Creation\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "def create_encoding_pipeline():\n",
                "    \"\"\"Create pipeline for encoding text.\"\"\"\n",
                "    return Pipeline(nodes=[encode_node])\n",
                "\n",
                "\n",
                "def create_search_pipeline():\n",
                "    \"\"\"Create pipeline for encoding query and searching.\"\"\"\n",
                "    return Pipeline(nodes=[encode_node, search_node])\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Test Functions\n",
                "# ============================================================================\n",
                "\n",
                "\n",
                "def test_sequential_engine():\n",
                "    \"\"\"Test with SeqEngine.\"\"\"\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"Testing with SeqEngine\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "    passages, queries = create_test_data(num_passages=10, num_queries=3)\n",
                "    encoder = MockEncoder(model_name=\"mock-encoder-v1\")\n",
                "\n",
                "    # Step 1: Encode all passages\n",
                "    print(f\"\\n[STEP 1] Encoding {len(passages)} passages...\")\n",
                "    encoding_pipeline = create_encoding_pipeline()\n",
                "\n",
                "    start_time = time.time()\n",
                "    passage_results = encoding_pipeline.map(\n",
                "        inputs={\"text\": passages, \"encoder\": encoder}, map_over=\"text\"\n",
                "    )\n",
                "    encoding_time = time.time() - start_time\n",
                "\n",
                "    passage_embeddings = [r[\"embedding\"] for r in passage_results]\n",
                "    print(f\"âœ… Encoded {len(passage_embeddings)} passages in {encoding_time:.3f}s\")\n",
                "\n",
                "    # Step 2: Search for each query\n",
                "    print(f\"\\n[STEP 2] Processing {len(queries)} queries...\")\n",
                "    search_pipeline = create_search_pipeline()\n",
                "    display(search_pipeline.visualize())\n",
                "\n",
                "    start_time = time.time()\n",
                "    search_results = search_pipeline.map(\n",
                "        inputs={\n",
                "            \"text\": queries,\n",
                "            \"encoder\": encoder,\n",
                "            \"passage_embeddings\": passage_embeddings,\n",
                "            \"passages\": passages,\n",
                "            \"top_k\": 3,\n",
                "        },\n",
                "        map_over=\"text\",\n",
                "    )\n",
                "    search_time = time.time() - start_time\n",
                "\n",
                "    print(f\"âœ… Searched {len(queries)} queries in {search_time:.3f}s\")\n",
                "\n",
                "    # Display results\n",
                "    print(\"\\n\" + \"-\" * 70)\n",
                "    print(\"Search Results:\")\n",
                "    print(\"-\" * 70)\n",
                "    for i, (query, result) in enumerate(zip(queries, search_results)):\n",
                "        print(f\"\\nQuery {i + 1}: {query}\")\n",
                "        print(\n",
                "            f\"Embedding: [{result['embedding'][0]:.3f}, {result['embedding'][1]:.3f}, ...]\"\n",
                "        )\n",
                "        print(\"Top matches:\")\n",
                "        for match in result[\"search_results\"]:\n",
                "            print(\n",
                "                f\"  {match['rank']}. [{match['score']:.3f}] {match['passage'][:60]}...\"\n",
                "            )\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(f\"Total time: {encoding_time + search_time:.3f}s\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "    return passage_embeddings, search_results\n",
                "\n",
                "\n",
                "def test_daft_engine():\n",
                "    \"\"\"Test with DaftEngine.\"\"\"\n",
                "    if not DAFT_AVAILABLE:\n",
                "        print(\"\\nâš ï¸  Skipping DaftEngine test (daft not installed)\")\n",
                "        return None, None\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"Testing with DaftEngine\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "    passages, queries = create_test_data(num_passages=10, num_queries=3)\n",
                "    encoder = MockEncoder(model_name=\"mock-encoder-v1\")\n",
                "\n",
                "    daft_engine = DaftEngine()\n",
                "\n",
                "    # Step 1: Encode all passages\n",
                "    print(f\"\\n[STEP 1] Encoding {len(passages)} passages with DaftEngine...\")\n",
                "    encoding_pipeline = create_encoding_pipeline()\n",
                "    encoding_pipeline.engine = daft_engine\n",
                "\n",
                "    start_time = time.time()\n",
                "    passage_results = encoding_pipeline.map(\n",
                "        inputs={\"text\": passages, \"encoder\": encoder}, map_over=\"text\"\n",
                "    )\n",
                "    encoding_time = time.time() - start_time\n",
                "\n",
                "    passage_embeddings = [r[\"embedding\"] for r in passage_results]\n",
                "    print(f\"âœ… Encoded {len(passage_embeddings)} passages in {encoding_time:.3f}s\")\n",
                "    print(\"   (Used batch function - check for fewer encoder calls!)\")\n",
                "\n",
                "    # Step 2: Search for each query\n",
                "    print(f\"\\n[STEP 2] Processing {len(queries)} queries with DaftEngine...\")\n",
                "    search_pipeline = create_search_pipeline()\n",
                "    search_pipeline.engine = daft_engine\n",
                "\n",
                "    start_time = time.time()\n",
                "    search_results = search_pipeline.map(\n",
                "        inputs={\n",
                "            \"text\": queries,\n",
                "            \"encoder\": encoder,\n",
                "            \"passage_embeddings\": passage_embeddings,\n",
                "            \"passages\": passages,\n",
                "            \"top_k\": 3,\n",
                "        },\n",
                "        map_over=\"text\",\n",
                "    )\n",
                "    search_time = time.time() - start_time\n",
                "\n",
                "    print(f\"âœ… Searched {len(queries)} queries in {search_time:.3f}s\")\n",
                "\n",
                "    # Display results\n",
                "    print(\"\\n\" + \"-\" * 70)\n",
                "    print(\"Search Results:\")\n",
                "    print(\"-\" * 70)\n",
                "    for i, (query, result) in enumerate(zip(queries, search_results)):\n",
                "        print(f\"\\nQuery {i + 1}: {query}\")\n",
                "        print(\n",
                "            f\"Embedding: [{result['embedding'][0]:.3f}, {result['embedding'][1]:.3f}, ...]\"\n",
                "        )\n",
                "        print(\"Top matches:\")\n",
                "        for match in result[\"search_results\"]:\n",
                "            print(\n",
                "                f\"  {match['rank']}. [{match['score']:.3f}] {match['passage'][:60]}...\"\n",
                "            )\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(f\"Total time: {encoding_time + search_time:.3f}s\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "    return passage_embeddings, search_results\n",
                "\n",
                "\n",
                "def verify_consistency(seq_results, daft_results):\n",
                "    \"\"\"Verify both engines produce same results.\"\"\"\n",
                "    if seq_results is None or daft_results is None:\n",
                "        return\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"Verifying Consistency Between Engines\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "    # Compare passage embeddings\n",
                "    seq_passages, seq_searches = seq_results\n",
                "    daft_passages, daft_searches = daft_results\n",
                "\n",
                "    print(f\"\\nâœ“ Both encoded {len(seq_passages)} passages\")\n",
                "\n",
                "    # Check if embeddings match\n",
                "    all_match = True\n",
                "    for i, (seq_emb, daft_emb) in enumerate(zip(seq_passages, daft_passages)):\n",
                "        if not np.allclose(seq_emb, daft_emb, atol=1e-6):\n",
                "            print(f\"  âš ï¸  Passage {i} embeddings differ!\")\n",
                "            all_match = False\n",
                "\n",
                "    if all_match:\n",
                "        print(\"  âœ… All passage embeddings match!\")\n",
                "\n",
                "    # Check search results\n",
                "    print(f\"\\nâœ“ Both processed {len(seq_searches)} queries\")\n",
                "\n",
                "    for i, (seq_res, daft_res) in enumerate(zip(seq_searches, daft_searches)):\n",
                "        # Check query embeddings\n",
                "        if not np.allclose(seq_res[\"embedding\"], daft_res[\"embedding\"], atol=1e-6):\n",
                "            print(f\"  âš ï¸  Query {i} embedding differs!\")\n",
                "            all_match = False\n",
                "\n",
                "        # Check search results\n",
                "        seq_passages_found = [r[\"passage\"] for r in seq_res[\"search_results\"]]\n",
                "        daft_passages_found = [r[\"passage\"] for r in daft_res[\"search_results\"]]\n",
                "\n",
                "        if seq_passages_found != daft_passages_found:\n",
                "            print(f\"  âš ï¸  Query {i} search results differ!\")\n",
                "            all_match = False\n",
                "\n",
                "    if all_match:\n",
                "        print(\"  âœ… All search results match!\")\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    if all_match:\n",
                "        print(\"ðŸŽ‰ SUCCESS: Both engines produce identical results!\")\n",
                "    else:\n",
                "        print(\"âš ï¸  WARNING: Some differences detected\")\n",
                "    print(\"=\" * 70)\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# Main\n",
                "# ============================================================================\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    print(\"=\" * 70)\n",
                "    print(\"Semantic Search Pipeline with DualNode\")\n",
                "    print(\"=\" * 70)\n",
                "    print(\"\\nThis demonstrates:\")\n",
                "    print(\"  - Batch-optimized encoding using DualNode\")\n",
                "    print(\"  - Semantic search with nearest neighbor retrieval\")\n",
                "    print(\"  - Comparison of SeqEngine vs DaftEngine\")\n",
                "\n",
                "    # Test with SeqEngine\n",
                "    seq_results = test_sequential_engine()\n",
                "\n",
                "    # Test with DaftEngine\n",
                "    # daft_results = test_daft_engine()\n",
                "\n",
                "    # Verify consistency\n",
                "    # verify_consistency(seq_results, daft_results)\n",
                "\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(\"âœ… All tests completed!\")\n",
                "    print(\"=\" * 70)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dc24edc",
            "metadata": {},
            "outputs": [],
            "source": [
                "from hypernodes import DualNode, node"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48535940",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List\n",
                "\n",
                "\n",
                "class Encoder:\n",
                "    def __init__(self, model_name: str):\n",
                "        self.model_name = model_name\n",
                "\n",
                "    def encode(self, text: str) -> List[float]:\n",
                "        return [0.1, 0.2, 0.3]\n",
                "\n",
                "    def encode_batch(self, texts: List[str]) -> List[List[float]]:\n",
                "        return [[0.1, 0.2, 0.3] for _ in texts]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "109842b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "@node(output_name=\"encoded_text\")\n",
                "def process(text: str, encoder: Encoder) -> List[float]:\n",
                "    return encoder.encode(text)\n",
                "\n",
                "\n",
                "pipeline = Pipeline(nodes=[process])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da00901d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div style=\"width:100%; overflow-x:auto; padding-bottom:8px;\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0.00 0.00 186.00 181.00\" style=\"width:min(100%, 210.80px);max-width:100%;height:auto;display:block;\">\n",
                            "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4.32 177.12)\">\n",
                            "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-4.32,4.32 -4.32,-177.12 181.61,-177.12 181.61,4.32 -4.32,4.32\" />\n",
                            "\n",
                            "<g id=\"node1\" class=\"node\">\n",
                            "<title>4501049648</title>\n",
                            "<path fill=\"#87ceeb\" stroke=\"black\" stroke-width=\"2\" d=\"M165.29,-57.4C165.29,-57.4 12,-57.4 12,-57.4 6,-57.4 0,-51.4 0,-45.4 0,-45.4 0,-12 0,-12 0,-6 6,0 12,0 12,0 165.29,0 165.29,0 171.29,0 177.29,-6 177.29,-12 177.29,-12 177.29,-45.4 177.29,-45.4 177.29,-51.4 171.29,-57.4 165.29,-57.4\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"62.77\" y=\"-34.85\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"13.00\">process</text>\n",
                            "<polygon fill=\"#87ceeb\" stroke=\"none\" points=\"11.52,-7.2 11.52,-28.7 165.77,-28.7 165.77,-7.2 11.52,-7.2\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"15.52\" y=\"-12.35\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">encoded_text : List[float]</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node2\" class=\"node\">\n",
                            "<title>group_4501049648</title>\n",
                            "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-width=\"2\" points=\"159.29,-172.8 18,-172.8 18,-115.4 159.29,-115.4 159.29,-172.8\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"64.64\" y=\"-149.25\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">text : str</text>\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"33.52\" y=\"-127.75\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">encoder : Encoder</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge1\" class=\"edge\">\n",
                            "<title>group_4501049648-&gt;4501049648</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M88.64,-114.48C88.64,-101.32 88.64,-85.46 88.64,-71.03\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"92.15,-71.33 88.65,-61.33 85.15,-71.33 92.15,-71.33\" />\n",
                            "</g>\n",
                            "</g>\n",
                            "</svg></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pipeline.visualize()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b947a3c5",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = pipeline.run(\n",
                "    inputs={\"text\": \"Hello, world!\", \"encoder\": Encoder(model_name=\"test\")}\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b7f2ac2b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'encoded_text': [0.1, 0.2, 0.3]}"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7486e8cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = pipeline.map(\n",
                "    inputs={\n",
                "        \"text\": [\"Hello, world!\", \"Hey! World\"],\n",
                "        \"encoder\": Encoder(model_name=\"test\"),\n",
                "    },\n",
                "    map_over=\"text\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e2c8eca6",
            "metadata": {},
            "source": [
                "# DualNode Example: Batch-Optimized Nodes\n",
                "\n",
                "DualNode allows you to define two implementations:\n",
                "- **singular**: For single-item execution (used in `.run()` and type hints)\n",
                "- **batch**: For optimized batch execution (used in `.map()` with DaftEngine)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a8ccc424",
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    from daft import Series\n",
                "except ImportError:\n",
                "    Series = list  # Fallback for type hints\n",
                "\n",
                "\n",
                "# Define singular and batch functions\n",
                "def encode_singular(text: str, encoder: Encoder) -> List[float]:\n",
                "    \"\"\"Process single item\"\"\"\n",
                "    return encoder.encode(text)\n",
                "\n",
                "\n",
                "def encode_batch(texts: Series, encoder: Encoder) -> Series:\n",
                "    \"\"\"Process batch of items - optimized\"\"\"\n",
                "    return Series.from_pylist([encoder.encode(t) for t in texts.to_pylist()])\n",
                "\n",
                "\n",
                "# Create DualNode\n",
                "dual_encode_node = DualNode(\n",
                "    output_name=\"encoded_text\",\n",
                "    singular=encode_singular,\n",
                "    batch=encode_batch,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad9697d4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div style=\"width:100%; overflow-x:auto; padding-bottom:8px;\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0.00 0.00 186.00 184.00\" style=\"width:min(100%, 210.80px);max-width:100%;height:auto;display:block;\">\n",
                            "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4.32 179.37)\">\n",
                            "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-4.32,4.32 -4.32,-179.37 181.61,-179.37 181.61,4.32 -4.32,4.32\" />\n",
                            "\n",
                            "<g id=\"node1\" class=\"node\">\n",
                            "<title>4591131088</title>\n",
                            "<path fill=\"#ffa07a\" stroke=\"black\" stroke-width=\"2\" d=\"M165.29,-59.65C165.29,-59.65 12,-59.65 12,-59.65 6,-59.65 0,-53.65 0,-47.65 0,-47.65 0,-12 0,-12 0,-6 6,0 12,0 12,0 165.29,0 165.29,0 171.29,0 177.29,-6 177.29,-12 177.29,-12 177.29,-47.65 177.29,-47.65 177.29,-53.65 171.29,-59.65 165.29,-59.65\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"28.27\" y=\"-37.1\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"13.00\">encode_singular â—†</text>\n",
                            "<polygon fill=\"#ffa07a\" stroke=\"none\" points=\"11.52,-7.2 11.52,-28.7 165.77,-28.7 165.77,-7.2 11.52,-7.2\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"15.52\" y=\"-12.35\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">encoded_text : List[float]</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node2\" class=\"node\">\n",
                            "<title>group_4591131088</title>\n",
                            "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-width=\"2\" points=\"159.29,-175.05 18,-175.05 18,-117.65 159.29,-117.65 159.29,-175.05\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"64.64\" y=\"-151.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">text : str</text>\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"33.52\" y=\"-130\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">encoder : Encoder</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge1\" class=\"edge\">\n",
                            "<title>group_4591131088-&gt;4591131088</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M88.64,-116.75C88.64,-103.56 88.64,-87.64 88.64,-73.1\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"92.15,-73.29 88.65,-63.29 85.15,-73.29 92.15,-73.29\" />\n",
                            "</g>\n",
                            "</g>\n",
                            "</svg></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Create pipeline with DualNode\n",
                "dual_pipeline = Pipeline(nodes=[dual_encode_node])\n",
                "dual_pipeline.visualize()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93d52534",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Single item result: {'encoded_text': [0.1, 0.2, 0.3]}\n"
                    ]
                }
            ],
            "source": [
                "# Test with .run() - uses singular function\n",
                "encoder = Encoder(model_name=\"test\")\n",
                "result = dual_pipeline.run(inputs={\"text\": \"Hello, world!\", \"encoder\": encoder})\n",
                "print(\"Single item result:\", result)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4a1944b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Batch results: [{'encoded_text': [0.1, 0.2, 0.3]}, {'encoded_text': [0.1, 0.2, 0.3]}, {'encoded_text': [0.1, 0.2, 0.3]}]\n"
                    ]
                }
            ],
            "source": [
                "# Test with .map() - uses batch function (optimized!)\n",
                "results = dual_pipeline.map(\n",
                "    inputs={\n",
                "        \"text\": [\"Hello\", \"World\", \"Test\"],\n",
                "        \"encoder\": encoder,\n",
                "    },\n",
                "    map_over=\"text\",\n",
                ")\n",
                "print(\"Batch results:\", results)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c5c211a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'encoded_text': [0.1, 0.2, 0.3]},\n",
                            " {'encoded_text': [0.1, 0.2, 0.3]},\n",
                            " {'encoded_text': [0.1, 0.2, 0.3]}]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hypernodes",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

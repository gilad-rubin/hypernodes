{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hypernodes Guide\n",
                "\n",
                "Hypernodes is a library for building robust, scalable data pipelines. It provides a structured way to define, execute, and orchestrate complex workflows, from simple functions to distributed cloud deployments.\n",
                "\n",
                "This guide covers:\n",
                "1.  **Core Concepts**: Nodes and Pipelines.\n",
                "2.  **Batch Processing**: Efficient iteration with `.map()`.\n",
                "3.  **State Management**: Handling heavy resources with `@stateful`.\n",
                "4.  **Advanced Orchestration**: Nested pipelines and async execution.\n",
                "5.  **Performance & Deployment**: `DualNode` optimization and Modal integration."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Core Concepts\n",
                "\n",
                "### Defining Nodes\n",
                "A **Node** is the fundamental unit of work in Hypernodes. It is a pure Python function decorated with `@node`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass\n",
                "from typing import List\n",
                "from hypernodes import Pipeline, node\n",
                "\n",
                "\n",
                "# --- Domain Objects ---\n",
                "@dataclass\n",
                "class Document:\n",
                "    text: str\n",
                "    score: float\n",
                "\n",
                "\n",
                "@dataclass\n",
                "class Answer:\n",
                "    text: str\n",
                "    sources: List[Document]\n",
                "\n",
                "\n",
                "# --- Mock Services ---\n",
                "class MockVectorDB:\n",
                "    def search(self, query: str, k: int) -> List[Document]:\n",
                "        return [Document(f\"Result for {query} #{i}\", 0.9 - i * 0.1) for i in range(k)]\n",
                "\n",
                "\n",
                "class MockLLM:\n",
                "    def generate(self, prompt: str) -> str:\n",
                "        return f\"LLM Answer based on: {prompt[:20]}...\"\n",
                "\n",
                "\n",
                "# --- Node Definitions ---\n",
                "\n",
                "\n",
                "@node(output_name=\"retrieved_docs\")\n",
                "def retrieve(query: str, vector_db: MockVectorDB, top_k: int = 2) -> List[Document]:\n",
                "    \"\"\"Retrieve relevant documents from the vector database.\"\"\"\n",
                "    return vector_db.search(query, k=top_k)\n",
                "\n",
                "\n",
                "@node(output_name=\"answer\")\n",
                "def generate(query: str, retrieved_docs: List[Document], llm: MockLLM) -> Answer:\n",
                "    \"\"\"Generate an answer using the retrieved documents.\"\"\"\n",
                "    context = \"\\n\".join([d.text for d in retrieved_docs])\n",
                "    response = llm.generate(f\"Context: {context} Question: {query}\")\n",
                "    return Answer(text=response, sources=retrieved_docs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Building and Running Pipelines\n",
                "A **Pipeline** orchestrates the execution of nodes. It automatically resolves dependencies based on input and output names."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize pipeline\n",
                "rag_pipeline = Pipeline(nodes=[retrieve, generate])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div style=\"width:100%; overflow-x:auto; padding-bottom:8px;\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0.00 0.00 469.00 297.00\" style=\"width:min(100%, 577.33px);max-width:100%;height:auto;display:block;\">\n",
                            "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4.32 292.52)\">\n",
                            "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-4.32,4.32 -4.32,-292.52 464.73,-292.52 464.73,4.32 -4.32,4.32\" />\n",
                            "\n",
                            "<g id=\"node1\" class=\"node\">\n",
                            "<title>4557163168</title>\n",
                            "<path fill=\"#87ceeb\" stroke=\"black\" stroke-width=\"2\" d=\"M351.91,-172.8C351.91,-172.8 155.88,-172.8 155.88,-172.8 149.88,-172.8 143.88,-166.8 143.88,-160.8 143.88,-160.8 143.88,-127.4 143.88,-127.4 143.88,-121.4 149.88,-115.4 155.88,-115.4 155.88,-115.4 351.91,-115.4 351.91,-115.4 357.91,-115.4 363.91,-121.4 363.91,-127.4 363.91,-127.4 363.91,-160.8 363.91,-160.8 363.91,-166.8 357.91,-172.8 351.91,-172.8\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"229.52\" y=\"-150.25\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"13.00\">retrieve</text>\n",
                            "<polygon fill=\"#87ceeb\" stroke=\"none\" points=\"155.39,-122.6 155.39,-144.1 352.39,-144.1 352.39,-122.6 155.39,-122.6\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"159.39\" y=\"-127.75\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">retrieved_docs : List[Document]</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node3\" class=\"node\">\n",
                            "<title>4459298496</title>\n",
                            "<path fill=\"#87ceeb\" stroke=\"black\" stroke-width=\"2\" d=\"M306.54,-57.4C306.54,-57.4 201.25,-57.4 201.25,-57.4 195.25,-57.4 189.25,-51.4 189.25,-45.4 189.25,-45.4 189.25,-12 189.25,-12 189.25,-6 195.25,0 201.25,0 201.25,0 306.54,0 306.54,0 312.54,0 318.54,-6 318.54,-12 318.54,-12 318.54,-45.4 318.54,-45.4 318.54,-51.4 312.54,-57.4 306.54,-57.4\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"225.77\" y=\"-34.85\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"13.00\">generate</text>\n",
                            "<polygon fill=\"#87ceeb\" stroke=\"none\" points=\"200.77,-7.2 200.77,-28.7 307.02,-28.7 307.02,-7.2 200.77,-7.2\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"204.77\" y=\"-12.35\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">answer : Answer</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge2\" class=\"edge\">\n",
                            "<title>4557163168-&gt;4459298496</title>\n",
                            "<path fill=\"none\" stroke=\"#333333\" stroke-width=\"2\" d=\"M253.89,-114.48C253.89,-101.32 253.89,-85.46 253.89,-71.03\" />\n",
                            "<polygon fill=\"#333333\" stroke=\"#333333\" stroke-width=\"2\" points=\"257.4,-71.33 253.9,-61.33 250.4,-71.33 257.4,-71.33\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node2\" class=\"node\">\n",
                            "<title>group_4557163168</title>\n",
                            "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-width=\"2\" points=\"341.54,-288.2 152.25,-288.2 152.25,-230.8 341.54,-230.8 341.54,-288.2\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"167.77\" y=\"-264.65\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">vector_db : MockVectorDB</text>\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"206.39\" y=\"-243.15\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">top_k : int = 2</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge5\" class=\"edge\">\n",
                            "<title>group_4557163168-&gt;4557163168</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M248.66,-229.88C249.47,-216.72 250.45,-200.86 251.34,-186.43\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"254.82,-186.92 251.94,-176.73 247.83,-186.49 254.82,-186.92\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node4\" class=\"node\">\n",
                            "<title>4466073424</title>\n",
                            "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" points=\"107.79,-162.1 0,-162.1 0,-126.1 107.79,-126.1 107.79,-162.1\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"53.89\" y=\"-138.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">llm : MockLLM</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge4\" class=\"edge\">\n",
                            "<title>4466073424-&gt;4459298496</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M85.59,-125.13C114.21,-108.9 157.14,-84.56 192.47,-64.53\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"194.05,-67.66 201.02,-59.68 190.59,-61.57 194.05,-67.66\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node5\" class=\"node\">\n",
                            "<title>4372168024</title>\n",
                            "<polygon fill=\"#90ee90\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" points=\"460.41,-277.5 377.38,-277.5 377.38,-241.5 460.41,-241.5 460.41,-277.5\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"418.89\" y=\"-253.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"13.00\">query : str</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge1\" class=\"edge\">\n",
                            "<title>4372168024-&gt;4557163168</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M392.75,-240.53C369.44,-224.51 334.64,-200.59 305.71,-180.71\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"308.06,-178.08 297.84,-175.3 304.1,-183.85 308.06,-178.08\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge3\" class=\"edge\">\n",
                            "<title>4372168024-&gt;4459298496</title>\n",
                            "<path fill=\"none\" stroke=\"#666666\" stroke-width=\"2\" d=\"M418.27,-240.52C416.45,-211.61 409.36,-154.12 381.89,-115.4 367.53,-95.15 346.76,-78.32 326.11,-65.09\" />\n",
                            "<polygon fill=\"#666666\" stroke=\"#666666\" stroke-width=\"2\" points=\"327.97,-62.12 317.61,-59.89 324.31,-68.09 327.97,-62.12\" />\n",
                            "</g>\n",
                            "</g>\n",
                            "</svg></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "rag_pipeline.visualize()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Answer: LLM Answer based on: Context: Result for ...\n"
                    ]
                }
            ],
            "source": [
                "# Initialize resources\n",
                "vector_db = MockVectorDB()\n",
                "llm = MockLLM()\n",
                "\n",
                "# Execute pipeline\n",
                "result = rag_pipeline.run(\n",
                "    inputs={\n",
                "        \"query\": \"What is Hypernodes?\",\n",
                "        \"vector_db\": vector_db,\n",
                "        \"llm\": llm,\n",
                "        \"top_k\": 2,\n",
                "    }\n",
                ")\n",
                "\n",
                "print(f\"Answer: {result['answer'].text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Batch Processing\n",
                "\n",
                "Hypernodes supports efficient batch processing using the `.map()` method. This allows you to iterate over a list of inputs while keeping other inputs constant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processed 3 queries.\n"
                    ]
                }
            ],
            "source": [
                "queries = [\"What is Python?\", \"How do pipelines work?\", \"Is this scalable?\"]\n",
                "\n",
                "results = rag_pipeline.map(\n",
                "    inputs={\n",
                "        \"query\": queries,\n",
                "        \"vector_db\": vector_db,  # Constant across all items\n",
                "        \"llm\": llm,\n",
                "        \"top_k\": 2,\n",
                "    },\n",
                "    map_over=\"query\",\n",
                ")\n",
                "\n",
                "print(f\"Processed {len(results)} queries.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cartesian Product Mapping\n",
                "Use `map_mode=\"product\"` to execute the pipeline over every combination of inputs, useful for grid searches or parameter sweeps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Grid results: [{'score': 10}, {'score': 20}, {'score': 20}, {'score': 40}]\n"
                    ]
                }
            ],
            "source": [
                "@node(output_name=\"score\")\n",
                "def evaluate_param(param_a: int, param_b: int) -> int:\n",
                "    return param_a * param_b\n",
                "\n",
                "\n",
                "grid_pipeline = Pipeline(nodes=[evaluate_param])\n",
                "\n",
                "# Executes 2 * 2 = 4 combinations\n",
                "grid_results = grid_pipeline.map(\n",
                "    inputs={\"param_a\": [1, 2], \"param_b\": [10, 20]},\n",
                "    map_over=[\"param_a\", \"param_b\"],\n",
                "    map_mode=\"product\",\n",
                ")\n",
                "print(f\"Grid results: {grid_results}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. State Management & Caching\n",
                "\n",
                "### Stateful Objects\n",
                "The `@stateful` decorator allows for lazy initialization of heavy resources (like ML models). These objects are initialized once per worker and reused."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model 'gpt-4-turbo'...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'prediction': 'Prediction from gpt-4-turbo for Hello'}"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from hypernodes import stateful\n",
                "\n",
                "\n",
                "@stateful\n",
                "class HeavyModel:\n",
                "    def __init__(self, model_name: str):\n",
                "        print(f\"Loading model '{model_name}'...\")\n",
                "        self.model_name = model_name\n",
                "\n",
                "    def predict(self, x: str) -> str:\n",
                "        return f\"Prediction from {self.model_name} for {x}\"\n",
                "\n",
                "\n",
                "@node(output_name=\"prediction\")\n",
                "def predict_node(x: str, model: HeavyModel) -> str:\n",
                "    return model.predict(x)\n",
                "\n",
                "\n",
                "model = HeavyModel(\"gpt-4-turbo\")\n",
                "pipeline = Pipeline(nodes=[predict_node])\n",
                "pipeline.run(inputs={\"x\": \"Hello\", \"model\": model})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Caching\n",
                "Attach a cache to the pipeline to persist results. This prevents re-computation when inputs have not changed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'prediction': 'Prediction from gpt-4-turbo for Hello'}"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from hypernodes import SequentialEngine\n",
                "from hypernodes.cache import DiskCache\n",
                "\n",
                "engine = SequentialEngine(cache=DiskCache(\".cache\"))\n",
                "pipeline = Pipeline(nodes=[predict_node], engine=engine)\n",
                "\n",
                "# Subsequent runs with the same inputs will retrieve results from cache\n",
                "pipeline.run(inputs={\"x\": \"Hello\", \"model\": model})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Advanced Orchestration\n",
                "\n",
                "### Nested Pipelines\n",
                "Pipelines can be encapsulated as nodes using `.as_node()`. This enables modular design and complex composition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wrap the RAG pipeline as a single node\n",
                "rag_node = rag_pipeline.as_node(\n",
                "    input_mapping={\"questions\": \"query\"},  # Map outer input to inner input\n",
                "    output_mapping={\"answer\": \"generated_answer\"},\n",
                "    map_over=\"questions\",  # Internal iteration\n",
                ")\n",
                "\n",
                "\n",
                "@node(output_name=\"score\")\n",
                "def evaluate(generated_answer: Answer) -> float:\n",
                "    return len(generated_answer.text) / 100.0\n",
                "\n",
                "\n",
                "eval_pipeline = Pipeline(nodes=[rag_node, evaluate])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Async Execution\n",
                "Nodes defined with `async def` are executed concurrently, making them ideal for I/O-bound operations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "\n",
                "\n",
                "@node(output_name=\"async_result\")\n",
                "async def fetch_data(url: str) -> str:\n",
                "    await asyncio.sleep(0.1)\n",
                "    return f\"Data from {url}\"\n",
                "\n",
                "\n",
                "async_pipeline = Pipeline(nodes=[fetch_data])\n",
                "\n",
                "results = async_pipeline.map(\n",
                "    inputs={\"url\": [\"google.com\", \"github.com\", \"modal.com\"]}, map_over=\"url\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Performance & Deployment\n",
                "\n",
                "### Optimization with DualNode\n",
                "`DualNode` allows defining both a singular (item-by-item) and a batch implementation for a node. Engines like `DaftEngine` can leverage the batch implementation for significant performance gains."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Daft installed, running DaftEngine example.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "126f3336b0fd47c48b4e81fe0e78937c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "ðŸ—¡ï¸ ðŸŸ InMemorySource: 00:00 "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "845da4788c7c41f48fe935ca9725a738",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "ðŸ—¡ï¸ ðŸŸ UDF compute-01a4a553-6dc0-4aaa-92b9-e832e60be4dd: 00:00 "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[{'doubled': 2}, {'doubled': 4}, {'doubled': 6}, {'doubled': 8}, {'doubled': 10}]\n"
                    ]
                }
            ],
            "source": [
                "from hypernodes import DualNode\n",
                "\n",
                "\n",
                "def compute_singular(x: int) -> int:\n",
                "    return x * 2\n",
                "\n",
                "\n",
                "def compute_batch(x_series):\n",
                "    # x_series is a Daft Series or Arrow Array\n",
                "    return x_series * 2\n",
                "\n",
                "\n",
                "fast_node = DualNode(\n",
                "    output_name=\"doubled\", singular=compute_singular, batch=compute_batch\n",
                ")\n",
                "\n",
                "try:\n",
                "    from hypernodes.engines import DaftEngine\n",
                "    import daft\n",
                "\n",
                "    print(\"Daft installed, running DaftEngine example.\")\n",
                "    fast_pipeline = Pipeline(nodes=[fast_node], engine=DaftEngine())\n",
                "    results = fast_pipeline.map(inputs={\"x\": [1, 2, 3, 4, 5]}, map_over=\"x\")\n",
                "    print(results)\n",
                "except ImportError:\n",
                "    print(\"Daft not installed, skipping DaftEngine execution example.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Observability\n",
                "Use `.visualize()` to inspect the pipeline graph and `ProgressCallback` for execution tracking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    from hypernodes.telemetry import ProgressCallback\n",
                "\n",
                "    engine = SequentialEngine(callbacks=[ProgressCallback()])\n",
                "    rag_pipeline_with_progress = Pipeline(nodes=[retrieve, generate], engine=engine)\n",
                "    rag_pipeline_with_progress.visualize()\n",
                "except ImportError:\n",
                "    print(\"tqdm not installed, skipping ProgressCallback example.\")\n",
                "except Exception as e:\n",
                "    print(f\"Visualization skipped: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "aa5e9a111cff4d1a850f0b941c34d9c9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "pipeline_4557320704   0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "863709ded6be4bb6bb163b8638b34601",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "retrieve   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "68e4bf1cd47a4f8e9516b1ef81812e93",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "generate   0%|          | 0/1 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "{'retrieved_docs': [Document(text='Result for What is Hypernodes? #0', score=0.9),\n",
                            "  Document(text='Result for What is Hypernodes? #1', score=0.8)],\n",
                            " 'answer': Answer(text='LLM Answer based on: Context: Result for ...', sources=[Document(text='Result for What is Hypernodes? #0', score=0.9), Document(text='Result for What is Hypernodes? #1', score=0.8)])}"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "rag_pipeline_with_progress.run(\n",
                "    inputs={\n",
                "        \"query\": \"What is Hypernodes?\",\n",
                "        \"vector_db\": vector_db,\n",
                "        \"llm\": llm,\n",
                "        \"top_k\": 2,\n",
                "    }\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

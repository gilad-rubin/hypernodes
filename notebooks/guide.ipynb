{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hypernodes Guide\n",
                "\n",
                "Hypernodes is a library for building robust, scalable data pipelines. It provides a structured way to define, execute, and orchestrate complex workflows, from simple functions to distributed cloud deployments.\n",
                "\n",
                "This guide covers:\n",
                "1.  **Core Concepts**: Nodes and Pipelines.\n",
                "2.  **Batch Processing**: Efficient iteration with `.map()`.\n",
                "3.  **State Management**: Handling heavy resources with `@stateful`.\n",
                "4.  **Advanced Orchestration**: Nested pipelines and async execution.\n",
                "5.  **Performance & Deployment**: `DualNode` optimization and Modal integration."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Core Concepts\n",
                "\n",
                "### Defining Nodes\n",
                "A **Node** is the fundamental unit of work in Hypernodes. It is a pure Python function decorated with `@node`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass\n",
                "from typing import List\n",
                "from hypernodes import Pipeline, node\n",
                "\n",
                "# --- Domain Objects ---\n",
                "@dataclass\n",
                "class Document:\n",
                "    text: str\n",
                "    score: float\n",
                "\n",
                "@dataclass\n",
                "class Answer:\n",
                "    text: str\n",
                "    sources: List[Document]\n",
                "\n",
                "# --- Mock Services ---\n",
                "class MockVectorDB:\n",
                "    def search(self, query: str, k: int) -> List[Document]:\n",
                "        return [Document(f\"Result for {query} #{i}\", 0.9 - i*0.1) for i in range(k)]\n",
                "\n",
                "class MockLLM:\n",
                "    def generate(self, prompt: str) -> str:\n",
                "        return f\"LLM Answer based on: {prompt[:20]}...\"\n",
                "\n",
                "# --- Node Definitions ---\n",
                "\n",
                "@node(output_name=\"retrieved_docs\")\n",
                "def retrieve(query: str, vector_db: MockVectorDB, top_k: int = 2) -> List[Document]:\n",
                "    \"\"\"Retrieve relevant documents from the vector database.\"\"\"\n",
                "    return vector_db.search(query, k=top_k)\n",
                "\n",
                "@node(output_name=\"answer\")\n",
                "def generate(query: str, retrieved_docs: List[Document], llm: MockLLM) -> Answer:\n",
                "    \"\"\"Generate an answer using the retrieved documents.\"\"\"\n",
                "    context = \"\\n\".join([d.text for d in retrieved_docs])\n",
                "    response = llm.generate(f\"Context: {context} Question: {query}\")\n",
                "    return Answer(text=response, sources=retrieved_docs)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Building and Running Pipelines\n",
                "A **Pipeline** orchestrates the execution of nodes. It automatically resolves dependencies based on input and output names."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize pipeline\n",
                "rag_pipeline = Pipeline(nodes=[retrieve, generate])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div style=\"width:100%; overflow-x:auto; padding-bottom:8px;\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0.00 0.00 443.00 310.00\" style=\"width:min(100%, 542.67px);max-width:100%;height:auto;display:block;\">\n",
                            "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4.32 305.66)\">\n",
                            "<polygon fill=\"#fafafa\" stroke=\"none\" points=\"-4.32,4.32 -4.32,-305.66 438.37,-305.66 438.37,4.32 -4.32,4.32\" />\n",
                            "\n",
                            "<g id=\"node1\" class=\"node\">\n",
                            "<title>4470248688</title>\n",
                            "<path fill=\"#e3f2fd\" stroke=\"black\" stroke-width=\"2\" d=\"M327.8,-181.56C327.8,-181.56 150.62,-181.56 150.62,-181.56 144.62,-181.56 138.62,-175.56 138.62,-169.56 138.62,-169.56 138.62,-131.78 138.62,-131.78 138.62,-125.78 144.62,-119.78 150.62,-119.78 150.62,-119.78 327.8,-119.78 327.8,-119.78 333.8,-119.78 339.8,-125.78 339.8,-131.78 339.8,-131.78 339.8,-169.56 339.8,-169.56 339.8,-175.56 333.8,-181.56 327.8,-181.56\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"217.84\" y=\"-158.52\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"12.00\">retrieve</text>\n",
                            "<polygon fill=\"#e3f2fd\" stroke=\"none\" points=\"151.59,-128.42 151.59,-150.67 326.84,-150.67 326.84,-128.42 151.59,-128.42\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"155.59\" y=\"-135.27\" font-family=\"Arial\" font-size=\"12.00\">retrieved_docs : List[Document]</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node3\" class=\"node\">\n",
                            "<title>4470254448</title>\n",
                            "<path fill=\"#e3f2fd\" stroke=\"black\" stroke-width=\"2\" d=\"M288.42,-61.78C288.42,-61.78 190,-61.78 190,-61.78 184,-61.78 178,-55.78 178,-49.78 178,-49.78 178,-12 178,-12 178,-6 184,0 190,0 190,0 288.42,0 288.42,0 294.42,0 300.42,-6 300.42,-12 300.42,-12 300.42,-49.78 300.42,-49.78 300.42,-55.78 294.42,-61.78 288.42,-61.78\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"214.09\" y=\"-38.74\" font-family=\"Arial\" font-weight=\"bold\" font-size=\"12.00\">generate</text>\n",
                            "<polygon fill=\"#e3f2fd\" stroke=\"none\" points=\"190.96,-8.64 190.96,-30.89 287.46,-30.89 287.46,-8.64 190.96,-8.64\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"194.96\" y=\"-15.49\" font-family=\"Arial\" font-size=\"12.00\">answer : Answer</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge2\" class=\"edge\">\n",
                            "<title>4470248688-&gt;4470254448</title>\n",
                            "<path fill=\"none\" stroke=\"#546e7a\" stroke-width=\"2\" d=\"M239.21,-119.03C239.21,-105.67 239.21,-89.77 239.21,-75.23\" />\n",
                            "<polygon fill=\"#546e7a\" stroke=\"#546e7a\" stroke-width=\"2\" points=\"242.71,-75.4 239.21,-65.4 235.71,-75.4 242.71,-75.4\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node2\" class=\"node\">\n",
                            "<title>group_4470248688</title>\n",
                            "<polygon fill=\"#f3e5f5\" stroke=\"black\" stroke-width=\"2\" points=\"320.67,-301.34 145.75,-301.34 145.75,-239.56 320.67,-239.56 320.67,-301.34\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"162.71\" y=\"-277.3\" font-family=\"Arial\" font-size=\"12.00\">vector_db : MockVectorDB</text>\n",
                            "<text xml:space=\"preserve\" text-anchor=\"start\" x=\"197.96\" y=\"-255.05\" font-family=\"Arial\" font-size=\"12.00\">top_k : int = 2</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge5\" class=\"edge\">\n",
                            "<title>group_4470248688-&gt;4470248688</title>\n",
                            "<path fill=\"none\" stroke=\"#90a4ae\" stroke-width=\"2\" d=\"M234.77,-238.81C235.45,-225.45 236.26,-209.55 237,-195.01\" />\n",
                            "<polygon fill=\"#90a4ae\" stroke=\"#90a4ae\" stroke-width=\"2\" points=\"240.49,-195.34 237.5,-185.18 233.5,-194.99 240.49,-195.34\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node4\" class=\"node\">\n",
                            "<title>4464501040</title>\n",
                            "<polygon fill=\"#f1f8e9\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" points=\"102.42,-168.67 0,-168.67 0,-132.67 102.42,-132.67 102.42,-168.67\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"51.21\" y=\"-146.4\" font-family=\"Arial\" font-size=\"12.00\">llm : MockLLM</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge4\" class=\"edge\">\n",
                            "<title>4464501040-&gt;4470254448</title>\n",
                            "<path fill=\"none\" stroke=\"#90a4ae\" stroke-width=\"2\" d=\"M79.76,-131.78C106.06,-115.3 145.94,-90.32 179.23,-69.47\" />\n",
                            "<polygon fill=\"#90a4ae\" stroke=\"#90a4ae\" stroke-width=\"2\" points=\"181.06,-72.45 187.67,-64.18 177.34,-66.52 181.06,-72.45\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"node5\" class=\"node\">\n",
                            "<title>4371889496</title>\n",
                            "<polygon fill=\"#f1f8e9\" stroke=\"black\" stroke-width=\"2\" stroke-dasharray=\"5,2\" points=\"434.05,-288.45 356.38,-288.45 356.38,-252.45 434.05,-252.45 434.05,-288.45\" />\n",
                            "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"395.21\" y=\"-266.18\" font-family=\"Arial\" font-size=\"12.00\">query : str</text>\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge1\" class=\"edge\">\n",
                            "<title>4371889496-&gt;4470248688</title>\n",
                            "<path fill=\"none\" stroke=\"#90a4ae\" stroke-width=\"2\" d=\"M371.52,-251.56C349.98,-235.3 317.47,-210.75 290.06,-190.07\" />\n",
                            "<polygon fill=\"#90a4ae\" stroke=\"#90a4ae\" stroke-width=\"2\" points=\"292.35,-187.41 282.26,-184.17 288.13,-192.99 292.35,-187.41\" />\n",
                            "</g>\n",
                            "\n",
                            "<g id=\"edge3\" class=\"edge\">\n",
                            "<title>4371889496-&gt;4470254448</title>\n",
                            "<path fill=\"none\" stroke=\"#90a4ae\" stroke-width=\"2\" d=\"M394.65,-251.77C392.93,-222.08 386,-161.41 358.21,-119.78 345.16,-100.22 326.22,-83.41 307.28,-69.89\" />\n",
                            "<polygon fill=\"#90a4ae\" stroke=\"#90a4ae\" stroke-width=\"2\" points=\"309.52,-67.18 299.29,-64.42 305.57,-72.96 309.52,-67.18\" />\n",
                            "</g>\n",
                            "</g>\n",
                            "</svg></div>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "rag_pipeline.visualize()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Answer: LLM Answer based on: Context: Result for ...\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Initialize resources\n",
                "vector_db = MockVectorDB()\n",
                "llm = MockLLM()\n",
                "\n",
                "# Execute pipeline\n",
                "result = rag_pipeline.run(inputs={\n",
                "    \"query\": \"What is Hypernodes?\",\n",
                "    \"vector_db\": vector_db,\n",
                "    \"llm\": llm,\n",
                "    \"top_k\": 2\n",
                "})\n",
                "\n",
                "print(f\"Answer: {result['answer'].text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Batch Processing\n",
                "\n",
                "Hypernodes supports efficient batch processing using the `.map()` method. This allows you to iterate over a list of inputs while keeping other inputs constant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processed 3 queries.\n"
                    ]
                }
            ],
            "source": [
                "queries = [\"What is Python?\", \"How do pipelines work?\", \"Is this scalable?\"]\n",
                "\n",
                "results = rag_pipeline.map(\n",
                "    inputs={\n",
                "        \"query\": queries,\n",
                "        \"vector_db\": vector_db, # Constant across all items\n",
                "        \"llm\": llm,\n",
                "        \"top_k\": 2\n",
                "    },\n",
                "    map_over=\"query\"\n",
                ")\n",
                "\n",
                "print(f\"Processed {len(results)} queries.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cartesian Product Mapping\n",
                "Use `map_mode=\"product\"` to execute the pipeline over every combination of inputs, useful for grid searches or parameter sweeps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Grid results: [{'score': 10}, {'score': 20}, {'score': 20}, {'score': 40}]\n"
                    ]
                }
            ],
            "source": [
                "@node(output_name=\"score\")\n",
                "def evaluate_param(param_a: int, param_b: int) -> int:\n",
                "    return param_a * param_b\n",
                "\n",
                "grid_pipeline = Pipeline(nodes=[evaluate_param])\n",
                "\n",
                "# Executes 2 * 2 = 4 combinations\n",
                "grid_results = grid_pipeline.map(\n",
                "    inputs={\"param_a\": [1, 2], \"param_b\": [10, 20]},\n",
                "    map_over=[\"param_a\", \"param_b\"],\n",
                "    map_mode=\"product\"\n",
                ")\n",
                "print(f\"Grid results: {grid_results}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. State Management & Caching\n",
                "\n",
                "### Stateful Objects\n",
                "The `@stateful` decorator allows for lazy initialization of heavy resources (like ML models). These objects are initialized once per worker and reused."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model 'gpt-4-turbo'...\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'prediction': 'Prediction from gpt-4-turbo for Hello'}"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from hypernodes import stateful\n",
                "\n",
                "@stateful\n",
                "class HeavyModel:\n",
                "    def __init__(self, model_name: str):\n",
                "        print(f\"Loading model '{model_name}'...\")\n",
                "        self.model_name = model_name\n",
                "\n",
                "    def predict(self, x: str) -> str:\n",
                "        return f\"Prediction from {self.model_name} for {x}\"\n",
                "\n",
                "@node(output_name=\"prediction\")\n",
                "def predict_node(x: str, model: HeavyModel) -> str:\n",
                "    return model.predict(x)\n",
                "\n",
                "model = HeavyModel(\"gpt-4-turbo\")\n",
                "pipeline = Pipeline(nodes=[predict_node])\n",
                "pipeline.run(inputs={\"x\": \"Hello\", \"model\": model})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Caching\n",
                "Attach a cache to the pipeline to persist results. This prevents re-computation when inputs have not changed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'prediction': 'Prediction from gpt-4-turbo for Hello'}"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from hypernodes.cache import DiskCache\n",
                "\n",
                "pipeline.with_cache(DiskCache(\"my_cache_dir\"))\n",
                "\n",
                "# Subsequent runs with the same inputs will retrieve results from cache\n",
                "pipeline.run(inputs={\"x\": \"Hello\", \"model\": model})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Advanced Orchestration\n",
                "\n",
                "### Nested Pipelines\n",
                "Pipelines can be encapsulated as nodes using `.as_node()`. This enables modular design and complex composition."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wrap the RAG pipeline as a single node\n",
                "rag_node = rag_pipeline.as_node(\n",
                "    input_mapping={\"questions\": \"query\"}, # Map outer input to inner input\n",
                "    output_mapping={\"answer\": \"generated_answer\"},\n",
                "    map_over=\"questions\" # Internal iteration\n",
                ")\n",
                "\n",
                "@node(output_name=\"score\")\n",
                "def evaluate(generated_answer: Answer) -> float:\n",
                "    return len(generated_answer.text) / 100.0\n",
                "\n",
                "eval_pipeline = Pipeline(nodes=[rag_node, evaluate])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Async Execution\n",
                "Nodes defined with `async def` are executed concurrently, making them ideal for I/O-bound operations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "\n",
                "@node(output_name=\"async_result\")\n",
                "async def fetch_data(url: str) -> str:\n",
                "    await asyncio.sleep(0.1)\n",
                "    return f\"Data from {url}\"\n",
                "\n",
                "async_pipeline = Pipeline(nodes=[fetch_data])\n",
                "\n",
                "results = async_pipeline.map(\n",
                "    inputs={\"url\": [\"google.com\", \"github.com\", \"modal.com\"]},\n",
                "    map_over=\"url\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Performance & Deployment\n",
                "\n",
                "### Optimization with DualNode\n",
                "`DualNode` allows defining both a singular (item-by-item) and a batch implementation for a node. Engines like `DaftEngine` can leverage the batch implementation for significant performance gains."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Daft installed, running DaftEngine example.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e5c46ec5f94846f4a51e101541991586",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "ðŸ—¡ï¸ ðŸŸ InMemorySource: 00:00 "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "35e55743f83a49fe83ed44deb5576902",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "ðŸ—¡ï¸ ðŸŸ UDF batch_wrapper-8ca1089c-3046-4910-a5b4-b7162af72df7: 00:00 "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Error when running pipeline node UDF batch_wrapper-8ca1089c-3046-4910-a5b4-b7162af72df7\n"
                    ]
                },
                {
                    "ename": "DaftCoreException",
                    "evalue": "DaftError::ValueError Cannot append column to RecordBatch of length 5 with column of length 10",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mDaftCoreException\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDaft installed, running DaftEngine example.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     fast_pipeline = Pipeline(nodes=[fast_node], engine=DaftEngine())\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mfast_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_over\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDaft not installed, skipping DaftEngine execution example.\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/pipeline.py:151\u001b[39m, in \u001b[36mPipeline.map\u001b[39m\u001b[34m(self, inputs, map_over, map_mode, output_name, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(map_over, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    149\u001b[39m     map_over = [map_over]\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_over\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/src/hypernodes/integrations/daft/engine.py:228\u001b[39m, in \u001b[36mDaftEngine.map\u001b[39m\u001b[34m(self, pipeline, inputs, map_over, map_mode, output_name, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     df = \u001b[38;5;28mself\u001b[39m._build_dataframe_from_plans(pipeline, execution_plans)\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# Collect (triggers execution)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     result_df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Reset context\u001b[39;00m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_map_context = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:4023\u001b[39m, in \u001b[36mDataFrame.collect\u001b[39m\u001b[34m(self, num_preview_rows)\u001b[39m\n\u001b[32m   3991\u001b[39m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[32m   3992\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_preview_rows: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[32m8\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33mDataFrame\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3993\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Executes the entire DataFrame and materializes the results.\u001b[39;00m\n\u001b[32m   3994\u001b[39m \n\u001b[32m   3995\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4021\u001b[39m \u001b[33;03m        (Showing first 3 of 3 rows)\u001b[39;00m\n\u001b[32m   4022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4023\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     dataframe_len = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._result)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:3986\u001b[39m, in \u001b[36mDataFrame._materialize_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3984\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Materializes the results of for this DataFrame and hold a pointer to the results.\"\"\"\u001b[39;00m\n\u001b[32m   3985\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m     \u001b[38;5;28mself\u001b[39m._result_cache = \u001b[43mget_or_create_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3987\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m   3988\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:74\u001b[39m, in \u001b[36mNativeRunner.run\u001b[39m\u001b[34m(self, builder)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) -> PartitionCacheEntry:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     result_pset = LocalPartitionSet()\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:115\u001b[39m, in \u001b[36mNativeRunner.run_iter\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m    106\u001b[39m results_gen = executor.run(\n\u001b[32m    107\u001b[39m     plan,\n\u001b[32m    108\u001b[39m     {k: v.values() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._part_set_cache.get_all_partition_sets().items()},\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mquery_id\u001b[39m\u001b[33m\"\u001b[39m: query_id},\n\u001b[32m    112\u001b[39m )\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults_gen\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_notify_result_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:70\u001b[39m, in \u001b[36mNativeExecutor.run\u001b[39m\u001b[34m(self, local_physical_plan, psets, ctx, results_buffer_size, context)\u001b[39m\n\u001b[32m     68\u001b[39m async_iter = LocalPartitionStream(get_or_init_event_loop().run(run_executor()))\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     part = \u001b[43mget_or_init_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_iter\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__anext__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m part \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     72\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/event_loop.py:28\u001b[39m, in \u001b[36mBackgroundEventLoop.run\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, future: Coroutine[Any, Any, Any]) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_coroutine_threadsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/python_workspace/hypernodes/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:38\u001b[39m, in \u001b[36mLocalPartitionStream.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PyMicroPartition:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.\u001b[34m__anext__\u001b[39m()\n",
                        "\u001b[31mDaftCoreException\u001b[39m: DaftError::ValueError Cannot append column to RecordBatch of length 5 with column of length 10"
                    ]
                }
            ],
            "source": [
                "from hypernodes import DualNode\n",
                "\n",
                "def compute_singular(x: int) -> int:\n",
                "    return x * 2\n",
                "\n",
                "def compute_batch(x_series):\n",
                "    # x_series is a Daft Series or Arrow Array\n",
                "    return x_series * 2\n",
                "\n",
                "fast_node = DualNode(\n",
                "    output_name=\"doubled\",\n",
                "    singular=compute_singular,\n",
                "    batch=compute_batch\n",
                ")\n",
                "\n",
                "try:\n",
                "    from hypernodes.engines import DaftEngine\n",
                "    import daft\n",
                "    print(\"Daft installed, running DaftEngine example.\")\n",
                "    fast_pipeline = Pipeline(nodes=[fast_node], engine=DaftEngine())\n",
                "    fast_pipeline.map(inputs={\"x\": [1, 2, 3, 4, 5]}, map_over=\"x\")\n",
                "except ImportError:\n",
                "    print(\"Daft not installed, skipping DaftEngine execution example.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Observability\n",
                "Use `.visualize()` to inspect the pipeline graph and `ProgressCallback` for execution tracking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    from hypernodes.telemetry import ProgressCallback\n",
                "    rag_pipeline.with_callbacks([ProgressCallback()])\n",
                "    rag_pipeline.visualize()\n",
                "except ImportError:\n",
                "    print(\"tqdm not installed, skipping ProgressCallback example.\")\n",
                "except Exception as e:\n",
                "    print(f\"Visualization skipped: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Modal Integration\n",
                "The `ModalBackend` enables seamless execution on Modal's cloud infrastructure without modifying your pipeline logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import modal\n",
                "from hypernodes import ModalBackend\n",
                "\n",
                "# 1. Define environment\n",
                "image = modal.Image.debian_slim().pip_install(\"hypernodes\")\n",
                "\n",
                "# 2. Create backend\n",
                "backend = ModalBackend(image=image)\n",
                "\n",
                "# 3. Attach and Run\n",
                "# rag_pipeline.with_backend(backend)\n",
                "# rag_pipeline.run(...) "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
